{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c135b76-8f7d-4843-a235-b42121a2c930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install einops\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da810ef8-a4a7-4db6-b3a4-39b0ae768a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from difflogic import LogicLayer, GroupSum\n",
    "import einops\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Literal\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d542b9f-15db-4847-84d0-73f9f03c4810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Base kernel count k = 16\n",
      "Expected shapes from paper:\n",
      "After conv1 + pool1: 16 × 12 × 12\n",
      "After conv2 + pool2: 48 × 6 × 6\n",
      "After conv3 + pool3: 144 × 3 × 3\n",
      "After flattening: 1296\n",
      "Training samples: 60000\n",
      "Test samples: 10000\n",
      "Model created with 596736 parameters\n",
      "\n",
      "================================================================================\n",
      "LOGIC GATE CONVOLUTIONAL DIFFLOGIC MNIST\n",
      "================================================================================\n",
      "Input: 1 × 28 × 28\n",
      "Conv1: 16 logic gate filters, 5×5, depth=3, no padding -> 16 × 24 × 24\n",
      "Pool1: OR pooling 2×2, stride 2 -> 16 × 12 × 12\n",
      "Conv2: 48 logic gate filters, 3×3, depth=3 -> 48 × 12 × 12\n",
      "Pool2: OR pooling 2×2, stride 2 -> 48 × 6 × 6\n",
      "Conv3: 144 logic gate filters, 3×3, depth=3 -> 144 × 6 × 6\n",
      "Pool3: OR pooling 2×2, stride 2 -> 144 × 3 × 3\n",
      "Flatten: -> 1296\n",
      "FC1: Regular differentiable logic layer 1296 -> 20480\n",
      "FC2: Regular differentiable logic layer 20480 -> 10240\n",
      "FC3: Regular differentiable logic layer 10240 -> 5120\n",
      "GroupSum: 5120 -> 10 classes\n",
      "================================================================================\n",
      "Starting training with logic gate convolutions...\n",
      "\n",
      "Epoch 1/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=1.2357, Acc=66.49%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.25it/s, Acc=81.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 81.31%\n",
      "Train Loss: 1.2357, Train Acc: 66.49%\n",
      "Test Loss: 0.6696, Test Acc: 81.31%\n",
      "\n",
      "Epoch 2/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5833, Acc=84.55%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.49it/s, Acc=88.50%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 88.50%\n",
      "Train Loss: 0.5833, Train Acc: 84.55%\n",
      "Test Loss: 0.4603, Test Acc: 88.50%\n",
      "\n",
      "Epoch 3/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.4446, Acc=88.75%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.39it/s, Acc=90.64%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 90.64%\n",
      "Train Loss: 0.4446, Train Acc: 88.75%\n",
      "Test Loss: 0.3871, Test Acc: 90.64%\n",
      "\n",
      "Epoch 4/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.3857, Acc=90.52%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.52it/s, Acc=91.49%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 91.49%\n",
      "Train Loss: 0.3857, Train Acc: 90.52%\n",
      "Test Loss: 0.3516, Test Acc: 91.49%\n",
      "\n",
      "Epoch 5/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:11<00:00,  4.55it/s, Loss=0.3538, Acc=91.49%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.25it/s, Acc=92.33%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 92.33%\n",
      "Train Loss: 0.3538, Train Acc: 91.49%\n",
      "Test Loss: 0.3311, Test Acc: 92.33%\n",
      "\n",
      "Epoch 6/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.3332, Acc=92.14%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.36it/s, Acc=92.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 92.82%\n",
      "Train Loss: 0.3332, Train Acc: 92.14%\n",
      "Test Loss: 0.3153, Test Acc: 92.82%\n",
      "\n",
      "Epoch 7/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.3190, Acc=92.55%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.25it/s, Acc=93.02%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 93.02%\n",
      "Train Loss: 0.3190, Train Acc: 92.55%\n",
      "Test Loss: 0.3054, Test Acc: 93.02%\n",
      "\n",
      "Epoch 8/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.3084, Acc=92.86%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.35it/s, Acc=93.21%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 93.21%\n",
      "Train Loss: 0.3084, Train Acc: 92.86%\n",
      "Test Loss: 0.2973, Test Acc: 93.21%\n",
      "\n",
      "Epoch 9/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.3005, Acc=93.05%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.29it/s, Acc=93.46%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 93.46%\n",
      "Train Loss: 0.3005, Train Acc: 93.05%\n",
      "Test Loss: 0.2911, Test Acc: 93.46%\n",
      "\n",
      "Epoch 10/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2947, Acc=93.24%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.40it/s, Acc=93.62%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 93.62%\n",
      "Train Loss: 0.2947, Train Acc: 93.24%\n",
      "Test Loss: 0.2871, Test Acc: 93.62%\n",
      "\n",
      "Epoch 11/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2902, Acc=93.44%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.29it/s, Acc=93.73%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 93.73%\n",
      "Train Loss: 0.2902, Train Acc: 93.44%\n",
      "Test Loss: 0.2836, Test Acc: 93.73%\n",
      "\n",
      "Epoch 12/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2860, Acc=93.57%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.33it/s, Acc=93.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 93.75%\n",
      "Train Loss: 0.2860, Train Acc: 93.57%\n",
      "Test Loss: 0.2803, Test Acc: 93.75%\n",
      "\n",
      "Epoch 13/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2826, Acc=93.65%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.47it/s, Acc=93.92%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 93.92%\n",
      "Train Loss: 0.2826, Train Acc: 93.65%\n",
      "Test Loss: 0.2777, Test Acc: 93.92%\n",
      "\n",
      "Epoch 14/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2795, Acc=93.74%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.40it/s, Acc=94.07%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.07%\n",
      "Train Loss: 0.2795, Train Acc: 93.74%\n",
      "Test Loss: 0.2741, Test Acc: 94.07%\n",
      "\n",
      "Epoch 15/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:11<00:00,  4.55it/s, Loss=0.2756, Acc=93.86%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.48it/s, Acc=94.07%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2756, Train Acc: 93.86%\n",
      "Test Loss: 0.2713, Test Acc: 94.07%\n",
      "\n",
      "Epoch 16/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2734, Acc=93.94%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.46it/s, Acc=94.10%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.10%\n",
      "Train Loss: 0.2734, Train Acc: 93.94%\n",
      "Test Loss: 0.2697, Test Acc: 94.10%\n",
      "\n",
      "Epoch 17/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2711, Acc=94.00%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.48it/s, Acc=94.13%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.13%\n",
      "Train Loss: 0.2711, Train Acc: 94.00%\n",
      "Test Loss: 0.2673, Test Acc: 94.13%\n",
      "\n",
      "Epoch 18/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2688, Acc=94.06%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.40it/s, Acc=94.14%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.14%\n",
      "Train Loss: 0.2688, Train Acc: 94.06%\n",
      "Test Loss: 0.2649, Test Acc: 94.14%\n",
      "\n",
      "Epoch 19/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2665, Acc=94.13%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.46it/s, Acc=94.22%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.22%\n",
      "Train Loss: 0.2665, Train Acc: 94.13%\n",
      "Test Loss: 0.2622, Test Acc: 94.22%\n",
      "\n",
      "Epoch 20/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2645, Acc=94.20%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.45it/s, Acc=94.26%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.26%\n",
      "Train Loss: 0.2645, Train Acc: 94.20%\n",
      "Test Loss: 0.2608, Test Acc: 94.26%\n",
      "\n",
      "Epoch 21/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2628, Acc=94.25%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.45it/s, Acc=94.42%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.42%\n",
      "Train Loss: 0.2628, Train Acc: 94.25%\n",
      "Test Loss: 0.2590, Test Acc: 94.42%\n",
      "\n",
      "Epoch 22/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2610, Acc=94.28%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.49it/s, Acc=94.41%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2610, Train Acc: 94.28%\n",
      "Test Loss: 0.2578, Test Acc: 94.41%\n",
      "\n",
      "Epoch 23/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2594, Acc=94.32%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.42it/s, Acc=94.43%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.43%\n",
      "Train Loss: 0.2594, Train Acc: 94.32%\n",
      "Test Loss: 0.2565, Test Acc: 94.43%\n",
      "\n",
      "Epoch 24/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2583, Acc=94.36%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.46it/s, Acc=94.46%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.46%\n",
      "Train Loss: 0.2583, Train Acc: 94.36%\n",
      "Test Loss: 0.2558, Test Acc: 94.46%\n",
      "\n",
      "Epoch 25/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2574, Acc=94.40%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.44it/s, Acc=94.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.54%\n",
      "Train Loss: 0.2574, Train Acc: 94.40%\n",
      "Test Loss: 0.2549, Test Acc: 94.54%\n",
      "\n",
      "Epoch 26/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2566, Acc=94.40%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.44it/s, Acc=94.62%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.62%\n",
      "Train Loss: 0.2566, Train Acc: 94.40%\n",
      "Test Loss: 0.2544, Test Acc: 94.62%\n",
      "\n",
      "Epoch 27/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2559, Acc=94.43%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.37it/s, Acc=94.55%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2559, Train Acc: 94.43%\n",
      "Test Loss: 0.2535, Test Acc: 94.55%\n",
      "\n",
      "Epoch 28/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2552, Acc=94.46%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.27it/s, Acc=94.59%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2552, Train Acc: 94.46%\n",
      "Test Loss: 0.2529, Test Acc: 94.59%\n",
      "\n",
      "Epoch 29/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2545, Acc=94.51%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.49it/s, Acc=94.53%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2545, Train Acc: 94.51%\n",
      "Test Loss: 0.2525, Test Acc: 94.53%\n",
      "\n",
      "Epoch 30/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2537, Acc=94.53%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.33it/s, Acc=94.69%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.69%\n",
      "Train Loss: 0.2537, Train Acc: 94.53%\n",
      "Test Loss: 0.2518, Test Acc: 94.69%\n",
      "\n",
      "Epoch 31/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2531, Acc=94.56%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.27it/s, Acc=94.69%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2531, Train Acc: 94.56%\n",
      "Test Loss: 0.2511, Test Acc: 94.69%\n",
      "\n",
      "Epoch 32/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2525, Acc=94.58%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.25it/s, Acc=94.72%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.72%\n",
      "Train Loss: 0.2525, Train Acc: 94.58%\n",
      "Test Loss: 0.2506, Test Acc: 94.72%\n",
      "\n",
      "Epoch 33/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2519, Acc=94.58%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.27it/s, Acc=94.72%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2519, Train Acc: 94.58%\n",
      "Test Loss: 0.2501, Test Acc: 94.72%\n",
      "\n",
      "Epoch 34/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2514, Acc=94.60%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.31it/s, Acc=94.80%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.80%\n",
      "Train Loss: 0.2514, Train Acc: 94.60%\n",
      "Test Loss: 0.2493, Test Acc: 94.80%\n",
      "\n",
      "Epoch 35/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2509, Acc=94.61%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.42it/s, Acc=94.81%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.81%\n",
      "Train Loss: 0.2509, Train Acc: 94.61%\n",
      "Test Loss: 0.2489, Test Acc: 94.81%\n",
      "\n",
      "Epoch 36/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2504, Acc=94.63%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.46it/s, Acc=94.80%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2504, Train Acc: 94.63%\n",
      "Test Loss: 0.2482, Test Acc: 94.80%\n",
      "\n",
      "Epoch 37/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2500, Acc=94.63%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.41it/s, Acc=94.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2500, Train Acc: 94.63%\n",
      "Test Loss: 0.2481, Test Acc: 94.75%\n",
      "\n",
      "Epoch 38/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2496, Acc=94.64%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.46it/s, Acc=94.76%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2496, Train Acc: 94.64%\n",
      "Test Loss: 0.2477, Test Acc: 94.76%\n",
      "\n",
      "Epoch 39/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2493, Acc=94.67%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.46it/s, Acc=94.78%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2493, Train Acc: 94.67%\n",
      "Test Loss: 0.2475, Test Acc: 94.78%\n",
      "\n",
      "Epoch 40/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2490, Acc=94.68%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.49it/s, Acc=94.80%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2490, Train Acc: 94.68%\n",
      "Test Loss: 0.2471, Test Acc: 94.80%\n",
      "\n",
      "Epoch 41/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2487, Acc=94.69%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.28it/s, Acc=94.77%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2487, Train Acc: 94.69%\n",
      "Test Loss: 0.2470, Test Acc: 94.77%\n",
      "\n",
      "Epoch 42/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2484, Acc=94.70%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.28it/s, Acc=94.84%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.84%\n",
      "Train Loss: 0.2484, Train Acc: 94.70%\n",
      "Test Loss: 0.2469, Test Acc: 94.84%\n",
      "\n",
      "Epoch 43/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2482, Acc=94.70%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.34it/s, Acc=94.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2482, Train Acc: 94.70%\n",
      "Test Loss: 0.2466, Test Acc: 94.79%\n",
      "\n",
      "Epoch 44/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2480, Acc=94.68%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.30it/s, Acc=94.81%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2480, Train Acc: 94.68%\n",
      "Test Loss: 0.2464, Test Acc: 94.81%\n",
      "\n",
      "Epoch 45/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2478, Acc=94.70%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.27it/s, Acc=94.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.86%\n",
      "Train Loss: 0.2478, Train Acc: 94.70%\n",
      "Test Loss: 0.2462, Test Acc: 94.86%\n",
      "\n",
      "Epoch 46/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2476, Acc=94.71%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.34it/s, Acc=94.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2476, Train Acc: 94.71%\n",
      "Test Loss: 0.2459, Test Acc: 94.79%\n",
      "\n",
      "Epoch 47/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2474, Acc=94.72%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.23it/s, Acc=94.81%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2474, Train Acc: 94.72%\n",
      "Test Loss: 0.2457, Test Acc: 94.81%\n",
      "\n",
      "Epoch 48/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2472, Acc=94.75%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.33it/s, Acc=94.85%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2472, Train Acc: 94.75%\n",
      "Test Loss: 0.2455, Test Acc: 94.85%\n",
      "\n",
      "Epoch 49/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2471, Acc=94.74%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.32it/s, Acc=94.84%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2471, Train Acc: 94.74%\n",
      "Test Loss: 0.2454, Test Acc: 94.84%\n",
      "\n",
      "Epoch 50/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2469, Acc=94.73%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.35it/s, Acc=94.84%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2469, Train Acc: 94.73%\n",
      "Test Loss: 0.2453, Test Acc: 94.84%\n",
      "\n",
      "Epoch 51/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2468, Acc=94.74%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.37it/s, Acc=94.89%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.89%\n",
      "Train Loss: 0.2468, Train Acc: 94.74%\n",
      "Test Loss: 0.2452, Test Acc: 94.89%\n",
      "\n",
      "Epoch 52/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2466, Acc=94.75%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.21it/s, Acc=94.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2466, Train Acc: 94.75%\n",
      "Test Loss: 0.2451, Test Acc: 94.88%\n",
      "\n",
      "Epoch 53/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2465, Acc=94.74%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.28it/s, Acc=94.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2465, Train Acc: 94.74%\n",
      "Test Loss: 0.2451, Test Acc: 94.88%\n",
      "\n",
      "Epoch 54/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2464, Acc=94.74%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.31it/s, Acc=94.91%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.91%\n",
      "Train Loss: 0.2464, Train Acc: 94.74%\n",
      "Test Loss: 0.2448, Test Acc: 94.91%\n",
      "\n",
      "Epoch 55/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2462, Acc=94.75%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.55it/s, Acc=94.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.93%\n",
      "Train Loss: 0.2462, Train Acc: 94.75%\n",
      "Test Loss: 0.2452, Test Acc: 94.93%\n",
      "\n",
      "Epoch 56/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2461, Acc=94.74%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.29it/s, Acc=94.87%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2461, Train Acc: 94.74%\n",
      "Test Loss: 0.2452, Test Acc: 94.87%\n",
      "\n",
      "Epoch 57/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2460, Acc=94.74%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.32it/s, Acc=94.84%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2460, Train Acc: 94.74%\n",
      "Test Loss: 0.2451, Test Acc: 94.84%\n",
      "\n",
      "Epoch 58/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2459, Acc=94.75%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.52it/s, Acc=94.83%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2459, Train Acc: 94.75%\n",
      "Test Loss: 0.2452, Test Acc: 94.83%\n",
      "\n",
      "Epoch 59/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2457, Acc=94.75%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.35it/s, Acc=94.81%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2457, Train Acc: 94.75%\n",
      "Test Loss: 0.2450, Test Acc: 94.81%\n",
      "\n",
      "Epoch 60/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:11<00:00,  4.55it/s, Loss=0.2455, Acc=94.74%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.49it/s, Acc=94.81%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2455, Train Acc: 94.74%\n",
      "Test Loss: 0.2450, Test Acc: 94.81%\n",
      "\n",
      "Epoch 61/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:11<00:00,  4.55it/s, Loss=0.2454, Acc=94.75%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.47it/s, Acc=94.87%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2454, Train Acc: 94.75%\n",
      "Test Loss: 0.2446, Test Acc: 94.87%\n",
      "\n",
      "Epoch 62/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2453, Acc=94.75%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.35it/s, Acc=94.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2453, Train Acc: 94.75%\n",
      "Test Loss: 0.2446, Test Acc: 94.88%\n",
      "\n",
      "Epoch 63/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2452, Acc=94.75%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.23it/s, Acc=94.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2452, Train Acc: 94.75%\n",
      "Test Loss: 0.2446, Test Acc: 94.88%\n",
      "\n",
      "Epoch 64/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2451, Acc=94.77%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.69it/s, Acc=94.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2451, Train Acc: 94.77%\n",
      "Test Loss: 0.2446, Test Acc: 94.86%\n",
      "\n",
      "Epoch 65/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:11<00:00,  4.55it/s, Loss=0.2450, Acc=94.77%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.42it/s, Acc=94.85%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2450, Train Acc: 94.77%\n",
      "Test Loss: 0.2445, Test Acc: 94.85%\n",
      "\n",
      "Epoch 66/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2449, Acc=94.77%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.26it/s, Acc=94.84%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2449, Train Acc: 94.77%\n",
      "Test Loss: 0.2444, Test Acc: 94.84%\n",
      "\n",
      "Epoch 67/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2448, Acc=94.78%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.30it/s, Acc=94.84%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2448, Train Acc: 94.78%\n",
      "Test Loss: 0.2444, Test Acc: 94.84%\n",
      "\n",
      "Epoch 68/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2448, Acc=94.76%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.29it/s, Acc=94.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2448, Train Acc: 94.76%\n",
      "Test Loss: 0.2443, Test Acc: 94.82%\n",
      "\n",
      "Epoch 69/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2447, Acc=94.78%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.24it/s, Acc=94.84%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2447, Train Acc: 94.78%\n",
      "Test Loss: 0.2442, Test Acc: 94.84%\n",
      "\n",
      "Epoch 70/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2446, Acc=94.77%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.32it/s, Acc=94.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2446, Train Acc: 94.77%\n",
      "Test Loss: 0.2440, Test Acc: 94.86%\n",
      "\n",
      "Epoch 71/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2445, Acc=94.77%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.33it/s, Acc=94.87%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2445, Train Acc: 94.77%\n",
      "Test Loss: 0.2440, Test Acc: 94.87%\n",
      "\n",
      "Epoch 72/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2444, Acc=94.78%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.33it/s, Acc=94.85%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2444, Train Acc: 94.78%\n",
      "Test Loss: 0.2439, Test Acc: 94.85%\n",
      "\n",
      "Epoch 73/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2444, Acc=94.78%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.30it/s, Acc=94.85%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2444, Train Acc: 94.78%\n",
      "Test Loss: 0.2438, Test Acc: 94.85%\n",
      "\n",
      "Epoch 74/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2443, Acc=94.77%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.31it/s, Acc=94.87%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2443, Train Acc: 94.77%\n",
      "Test Loss: 0.2438, Test Acc: 94.87%\n",
      "\n",
      "Epoch 75/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2442, Acc=94.78%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.27it/s, Acc=94.87%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2442, Train Acc: 94.78%\n",
      "Test Loss: 0.2437, Test Acc: 94.87%\n",
      "\n",
      "Epoch 76/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2441, Acc=94.80%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.29it/s, Acc=94.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2441, Train Acc: 94.80%\n",
      "Test Loss: 0.2434, Test Acc: 94.86%\n",
      "\n",
      "Epoch 77/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2440, Acc=94.79%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.24it/s, Acc=94.87%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2440, Train Acc: 94.79%\n",
      "Test Loss: 0.2434, Test Acc: 94.87%\n",
      "\n",
      "Epoch 78/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.2439, Acc=94.81%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.23it/s, Acc=94.90%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2439, Train Acc: 94.81%\n",
      "Test Loss: 0.2432, Test Acc: 94.90%\n",
      "\n",
      "Epoch 79/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2437, Acc=94.81%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.32it/s, Acc=94.90%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2437, Train Acc: 94.81%\n",
      "Test Loss: 0.2431, Test Acc: 94.90%\n",
      "\n",
      "Epoch 80/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2435, Acc=94.81%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.33it/s, Acc=94.89%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2435, Train Acc: 94.81%\n",
      "Test Loss: 0.2428, Test Acc: 94.89%\n",
      "\n",
      "Epoch 81/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2434, Acc=94.83%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.44it/s, Acc=94.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2434, Train Acc: 94.83%\n",
      "Test Loss: 0.2428, Test Acc: 94.88%\n",
      "\n",
      "Epoch 82/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2433, Acc=94.83%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.27it/s, Acc=94.91%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2433, Train Acc: 94.83%\n",
      "Test Loss: 0.2427, Test Acc: 94.91%\n",
      "\n",
      "Epoch 83/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2433, Acc=94.83%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.30it/s, Acc=94.85%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2433, Train Acc: 94.83%\n",
      "Test Loss: 0.2427, Test Acc: 94.85%\n",
      "\n",
      "Epoch 84/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2432, Acc=94.83%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.27it/s, Acc=94.84%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2432, Train Acc: 94.83%\n",
      "Test Loss: 0.2427, Test Acc: 94.84%\n",
      "\n",
      "Epoch 85/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2431, Acc=94.83%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.32it/s, Acc=94.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2431, Train Acc: 94.83%\n",
      "Test Loss: 0.2427, Test Acc: 94.86%\n",
      "\n",
      "Epoch 86/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2431, Acc=94.84%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.40it/s, Acc=94.85%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2431, Train Acc: 94.84%\n",
      "Test Loss: 0.2426, Test Acc: 94.85%\n",
      "\n",
      "Epoch 87/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2430, Acc=94.85%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.47it/s, Acc=94.87%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2430, Train Acc: 94.85%\n",
      "Test Loss: 0.2426, Test Acc: 94.87%\n",
      "\n",
      "Epoch 88/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2430, Acc=94.84%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.46it/s, Acc=94.91%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2430, Train Acc: 94.84%\n",
      "Test Loss: 0.2425, Test Acc: 94.91%\n",
      "\n",
      "Epoch 89/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2429, Acc=94.85%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.46it/s, Acc=94.92%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2429, Train Acc: 94.85%\n",
      "Test Loss: 0.2427, Test Acc: 94.92%\n",
      "\n",
      "Epoch 90/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2428, Acc=94.84%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.41it/s, Acc=94.90%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2428, Train Acc: 94.84%\n",
      "Test Loss: 0.2426, Test Acc: 94.90%\n",
      "\n",
      "Epoch 91/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2428, Acc=94.85%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.46it/s, Acc=94.90%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2428, Train Acc: 94.85%\n",
      "Test Loss: 0.2426, Test Acc: 94.90%\n",
      "\n",
      "Epoch 92/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2427, Acc=94.86%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.23it/s, Acc=94.92%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2427, Train Acc: 94.86%\n",
      "Test Loss: 0.2425, Test Acc: 94.92%\n",
      "\n",
      "Epoch 93/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2427, Acc=94.86%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.28it/s, Acc=94.90%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2427, Train Acc: 94.86%\n",
      "Test Loss: 0.2424, Test Acc: 94.90%\n",
      "\n",
      "Epoch 94/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2426, Acc=94.85%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.41it/s, Acc=94.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2426, Train Acc: 94.85%\n",
      "Test Loss: 0.2424, Test Acc: 94.93%\n",
      "\n",
      "Epoch 95/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2426, Acc=94.86%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.42it/s, Acc=94.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2426, Train Acc: 94.86%\n",
      "Test Loss: 0.2423, Test Acc: 94.93%\n",
      "\n",
      "Epoch 96/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:11<00:00,  4.55it/s, Loss=0.2426, Acc=94.86%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.41it/s, Acc=94.95%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 94.95%\n",
      "Train Loss: 0.2426, Train Acc: 94.86%\n",
      "Test Loss: 0.2423, Test Acc: 94.95%\n",
      "\n",
      "Epoch 97/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.2425, Acc=94.86%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.45it/s, Acc=94.95%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2425, Train Acc: 94.86%\n",
      "Test Loss: 0.2423, Test Acc: 94.95%\n",
      "\n",
      "Epoch 98/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2425, Acc=94.87%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.29it/s, Acc=94.92%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2425, Train Acc: 94.87%\n",
      "Test Loss: 0.2423, Test Acc: 94.92%\n",
      "\n",
      "Epoch 99/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2425, Acc=94.86%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.28it/s, Acc=94.92%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2425, Train Acc: 94.86%\n",
      "Test Loss: 0.2422, Test Acc: 94.92%\n",
      "\n",
      "Epoch 100/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.2425, Acc=94.85%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.34it/s, Acc=94.91%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2425, Train Acc: 94.85%\n",
      "Test Loss: 0.2422, Test Acc: 94.91%\n",
      "\n",
      "Training completed in 13645.03 seconds\n",
      "Best test accuracy: 94.95%\n",
      "\n",
      "Testing discrete inference...\n",
      "Discrete inference accuracy: 94.91%\n",
      "Inference speed: 0.000404 seconds per sample\n",
      "\n",
      "================================================================================\n",
      "LOGIC GATE CONVOLUTIONAL DIFFLOGIC MNIST RESULTS\n",
      "================================================================================\n",
      "Architecture: Custom logic gate convolutions + DiffLogic FC layers\n",
      "Base kernel count (k): 16\n",
      "Total parameters: 596,736\n",
      "Training epochs: 100\n",
      "Best test accuracy: 94.95%\n",
      "Final test accuracy: 94.91%\n",
      "Inference speed: 0.000404 seconds per sample\n",
      "\n",
      "Logic gate convolutions replace traditional conv layers with:\n",
      "- 16 different logic gates (AND, OR, XOR, NOT, etc.)\n",
      "- Tree-structured logic processing with configurable depth\n",
      "- Soft logic during training, hard logic during inference\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Type definitions\n",
    "InitializationType = Literal['residual', 'random']\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "k = 16  # Base number of kernels (from paper: k=16 for small model)\n",
    "\n",
    "print(f\"Base kernel count k = {k}\")\n",
    "print(f\"Expected shapes from paper:\")\n",
    "print(f\"After conv1 + pool1: {k} × 12 × 12\")\n",
    "print(f\"After conv2 + pool2: {3*k} × 6 × 6\") \n",
    "print(f\"After conv3 + pool3: {9*k} × 3 × 3\")\n",
    "print(f\"After flattening: {81*k}\")\n",
    "\n",
    "# Data loading and preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Logic gate definitions\n",
    "logic_gates = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "\n",
    "def apply_logic_gate(a: torch.Tensor, b: torch.Tensor, logic_gate: int):\n",
    "    return {\n",
    "        0:  torch.zeros_like(a),\n",
    "        1:  a * b,\n",
    "        2:  a - a * b,\n",
    "        3:  a,\n",
    "        4:  b - a * b,\n",
    "        5:  b,\n",
    "        6:  a + b - 2 * a * b,\n",
    "        7:  a + b - a * b,\n",
    "        8:  1 - (a + b - a * b),\n",
    "        9:  1 - (a + b - 2 * a * b),\n",
    "        10: 1 - b,\n",
    "        11: 1 - b + a * b,\n",
    "        12: 1 - a,\n",
    "        13: 1 - a + a * b,\n",
    "        14: 1 - a * b,\n",
    "        15: torch.ones_like(a),\n",
    "    }[logic_gate]\n",
    "\n",
    "class Logic(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim: int,\n",
    "                 out_dim: int,\n",
    "                 initialization_type: InitializationType = 'residual',\n",
    "                 device=None\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.initialization_type = initialization_type\n",
    "        self.device = device or torch.device('cpu')\n",
    "        \n",
    "        a, b = self.get_connections()\n",
    "        self.register_buffer('a', a)\n",
    "        self.register_buffer('b', b)\n",
    "        \n",
    "        weights = torch.randn(out_dim, len(logic_gates), device=self.device)\n",
    "        if self.initialization_type == 'residual':\n",
    "            weights[:, :] = 0\n",
    "            weights[:, 3] = 5  # Initialize to identity gate\n",
    "        self.weights = torch.nn.parameter.Parameter(weights)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        a, b = x[:, self.a, ...], x[:, self.b, ...]\n",
    "        \n",
    "        if self.training:\n",
    "            normalized_weights = torch.nn.functional.softmax(self.weights, dim=-1).to(x.dtype).to(self.device)\n",
    "            r = torch.zeros_like(a).to(x.dtype).to(self.device)\n",
    "            for logic_gate in logic_gates:\n",
    "                if len(a.shape) > 2:\n",
    "                    nw = einops.repeat(normalized_weights[..., logic_gate], 'weights -> weights depth', depth=a.shape[-1])\n",
    "                else:\n",
    "                    nw = normalized_weights[..., logic_gate]\n",
    "                r = r + nw * apply_logic_gate(a, b, logic_gate)\n",
    "            return r\n",
    "        else:\n",
    "            one_hot_weights = torch.nn.functional.one_hot(self.weights.argmax(-1), len(logic_gates)).to(torch.float32).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                r = torch.zeros_like(a).to(x.dtype).to(self.device)\n",
    "                for logic_gate in logic_gates:\n",
    "                    if len(a.shape) > 2:\n",
    "                        ohw = einops.repeat(one_hot_weights[..., logic_gate], 'weights -> weights depth', depth=a.shape[-1])\n",
    "                    else:\n",
    "                        ohw = one_hot_weights[..., logic_gate]\n",
    "                    r = r + ohw * apply_logic_gate(a, b, logic_gate)\n",
    "                return r\n",
    "\n",
    "    def get_connections(self):\n",
    "        connections = torch.randperm(2 * self.out_dim) % self.in_dim\n",
    "        connections = torch.randperm(self.in_dim)[connections]\n",
    "        connections = connections.reshape(2, self.out_dim)\n",
    "        a, b = connections[0], connections[1]\n",
    "        a, b = a.to(torch.int64), b.to(torch.int64)\n",
    "        a, b = a.to(self.device), b.to(self.device)\n",
    "        return a, b\n",
    "\n",
    "class LogicTree(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim: int,\n",
    "                 depth: int = 3,\n",
    "                 initialization_type: InitializationType = 'residual',\n",
    "                 device=None,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.device = device or torch.device('cpu')\n",
    "        \n",
    "        layers = [LogicLayer(in_dim, int(2 ** (depth - 1)), initialization_type=initialization_type, device=self.device,implementation='cuda' if device.type == 'cuda' else 'python',\n",
    "                    connections='random',grad_factor=1.5 )]\n",
    "        for i in range(0, depth - 1, 1):\n",
    "            layers.append(LogicLayer(int(2 ** (depth - 1 - i)), int(2 ** (depth - 1 - i - 1)), \n",
    "                            initialization_type=initialization_type, device=self.device,implementation='cuda' if device.type == 'cuda' else 'python',\n",
    "                            connections='random',grad_factor=1.5))\n",
    "        \n",
    "        self.tree = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.tree(x)\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 depth: int = 3,\n",
    "                 kernel_size: int = 3,\n",
    "                 stride: int = 1,\n",
    "                 padding: int = 1,\n",
    "                 initialization_type: InitializationType = 'residual',\n",
    "                 device=None\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.device = device or torch.device('cpu')\n",
    "        \n",
    "        self.filters = nn.ModuleList([\n",
    "            LogicTree(in_dim=kernel_size ** 2 * in_channels, depth=depth, \n",
    "                     initialization_type=initialization_type, device=self.device) \n",
    "            for _ in range(out_channels)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, _, height, width = x.shape\n",
    "        x = F.pad(x, (self.padding, self.padding, self.padding, self.padding), mode='constant', value=0)\n",
    "        out_height = (height + 2 * self.padding - self.kernel_size) // self.stride + 1\n",
    "        out_width = (width + 2 * self.padding - self.kernel_size) // self.stride + 1\n",
    "        patches = F.unfold(x, kernel_size=self.kernel_size, stride=self.stride)\n",
    "        outputs = []\n",
    "        \n",
    "        patches = einops.rearrange(patches, 'b h w -> (b w) h', h=patches.shape[1], w=patches.shape[2]) # Input is (100,25,576) Output: (57600,25)\n",
    "        for filter in self.filters:\n",
    "            out = filter(patches)  # Shape: (batch_size, 1, out_height * out_width)\n",
    "            out = einops.rearrange(out, '(b h w) 1 -> b (h w)', h=out_height, w=out_width)\n",
    "            outputs.append(out)\n",
    "        \n",
    "        output_tensor = torch.stack(outputs, dim=1)  # Shape: (batch_size, out_channels, out_height * out_width)\n",
    "        output_tensor = einops.rearrange(output_tensor, 'b c (h w) -> b c h w', h=out_height, w=out_width)\n",
    "        return output_tensor\n",
    "\n",
    "class CustomOrPool2d(nn.Module):\n",
    "    def __init__(self, kernel_size=2, stride=2, padding=0):\n",
    "        super(CustomOrPool2d, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Use MaxPool2d as approximation to OR pooling\n",
    "        # In binary logic, max operation approximates OR\n",
    "        return torch.max_pool2d(x, self.kernel_size, self.stride, self.padding)\n",
    "\n",
    "\n",
    "\n",
    "class ConvDiffLogicMNIST(nn.Module):\n",
    "    def __init__(self, k=16):\n",
    "        super(ConvDiffLogicMNIST, self).__init__()\n",
    "        self.k = k\n",
    "        \n",
    "        # Convolutional block 1: k kernels, 5x5, depth=3, no padding\n",
    "        # Input: 1 × 28 × 28 -> Output: k × 24 × 24 (28-5+1=24)\n",
    "        self.conv1 = Conv(in_channels=1, out_channels=k, kernel_size=5, depth=3, \n",
    "                         padding=0, initialization_type='residual', device=device)\n",
    "        \n",
    "        # OR pooling 1: 2x2, stride 2\n",
    "        # k × 24 × 24 -> k × 12 × 12\n",
    "        self.pool1 = CustomOrPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Convolutional block 2: 3*k kernels, 3x3, depth=3\n",
    "        # k × 12 × 12 -> 3*k × 12 × 12 (with padding=1), then pooled to 3*k × 6 × 6\n",
    "        self.conv2 = Conv(in_channels=k, out_channels=3*k, kernel_size=3, depth=3, \n",
    "                         padding=1, initialization_type='residual', device=device)\n",
    "        \n",
    "        # OR pooling 2: 2x2, stride 2\n",
    "        # 3*k × 12 × 12 -> 3*k × 6 × 6\n",
    "        self.pool2 = CustomOrPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Convolutional block 3: 9*k kernels, 3x3, depth=3\n",
    "        # 3*k × 6 × 6 -> 9*k × 6 × 6 (with padding=1), then pooled to 9*k × 3 × 3\n",
    "        self.conv3 = Conv(in_channels=3*k, out_channels=9*k, kernel_size=3, depth=3, \n",
    "                         padding=1, initialization_type='residual', device=device)\n",
    "        \n",
    "        # OR pooling 3: 2x2, stride 2\n",
    "        # 9*k × 6 × 6 -> 9*k × 3 × 3\n",
    "        self.pool3 = CustomOrPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Flatten: 9*k × 3 × 3 -> 81*k\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Regular differentiable logic layers (as specified in paper)\n",
    "        # 81*k → 1280*k\n",
    "        self.fc1 = LogicLayer(\n",
    "            in_dim=81*k,\n",
    "            out_dim=1280*k,\n",
    "            device=device,\n",
    "            implementation='cuda' if device.type == 'cuda' else 'python',\n",
    "            connections='random',\n",
    "            grad_factor=1.5 , # Higher for deeper networks\n",
    "        )\n",
    "        \n",
    "        # 1280*k → 640*k\n",
    "        self.fc2 = LogicLayer(\n",
    "            in_dim=1280*k,\n",
    "            out_dim=640*k,\n",
    "            device=device,\n",
    "            implementation='cuda' if device.type == 'cuda' else 'python',\n",
    "            connections='random',\n",
    "            grad_factor=1.5\n",
    "        )\n",
    "        \n",
    "        # 640*k → 320*k\n",
    "        self.fc3 = LogicLayer(\n",
    "            in_dim=640*k,\n",
    "            out_dim=320*k,\n",
    "            device=device,\n",
    "            implementation='cuda' if device.type == 'cuda' else 'python',\n",
    "            connections='random',\n",
    "            grad_factor=1.5\n",
    "        )\n",
    "        \n",
    "        # GroupSum: 320*k → 10 (10 classes)\n",
    "        # Using tau=30 as in the paper specifications\n",
    "        self.group_sum = GroupSum(k=10, tau=30)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input thresholding for binary processing (as mentioned in paper)\n",
    "        # The paper mentions using binary inputs\n",
    "        x = (x > 0.5).float()\n",
    "        \n",
    "        # Debug shape printing (uncomment for debugging)\n",
    "        # print(f\"Input shape: {x.shape}\")\n",
    "        \n",
    "        # Convolutional processing with logic gates\n",
    "        x = self.conv1(x)\n",
    "        # print(f\"After conv1: {x.shape}\")\n",
    "        \n",
    "        x = self.pool1(x)\n",
    "        # print(f\"After pool1: {x.shape}\")\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        # print(f\"After conv2: {x.shape}\")\n",
    "        \n",
    "        x = self.pool2(x)\n",
    "        # print(f\"After pool2: {x.shape}\")\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        # print(f\"After conv3: {x.shape}\")\n",
    "        \n",
    "        x = self.pool3(x)\n",
    "        # print(f\"After pool3: {x.shape}\")\n",
    "        \n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "        # print(f\"After flatten: {x.shape}\")\n",
    "        \n",
    "        # Fully connected logic layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # GroupSum for classification\n",
    "        x = self.group_sum(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = ConvDiffLogicMNIST(k=k).to(device)\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "\n",
    "# Print architecture details\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOGIC GATE CONVOLUTIONAL DIFFLOGIC MNIST\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Input: 1 × 28 × 28\")\n",
    "print(f\"Conv1: {k} logic gate filters, 5×5, depth=3, no padding -> {k} × 24 × 24\")\n",
    "print(f\"Pool1: OR pooling 2×2, stride 2 -> {k} × 12 × 12\")\n",
    "print(f\"Conv2: {3*k} logic gate filters, 3×3, depth=3 -> {3*k} × 12 × 12\")\n",
    "print(f\"Pool2: OR pooling 2×2, stride 2 -> {3*k} × 6 × 6\")\n",
    "print(f\"Conv3: {9*k} logic gate filters, 3×3, depth=3 -> {9*k} × 6 × 6\")\n",
    "print(f\"Pool3: OR pooling 2×2, stride 2 -> {9*k} × 3 × 3\")\n",
    "print(f\"Flatten: -> {81*k}\")\n",
    "print(f\"FC1: Regular differentiable logic layer {81*k} -> {1280*k}\")\n",
    "print(f\"FC2: Regular differentiable logic layer {1280*k} -> {640*k}\")\n",
    "print(f\"FC3: Regular differentiable logic layer {640*k} -> {320*k}\")\n",
    "print(f\"GroupSum: {320*k} -> 10 classes\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc='Training')\n",
    "    for batch_idx, (data, target) in enumerate(progress_bar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
    "            'Acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    return running_loss / len(train_loader), 100. * correct / total\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(test_loader, desc='Testing')\n",
    "        for data, target in progress_bar:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'Acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    return test_loss / len(test_loader), 100. * correct / total\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Starting training with logic gate convolutions...\")\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    best_test_acc = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        \n",
    "        # Evaluate\n",
    "        test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        # Save best model\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            torch.save(model.state_dict(), 'best_logic_conv_difflogic_mnist.pth')\n",
    "            print(f\"New best model saved! Test accuracy: {test_acc:.2f}%\")\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {total_time:.2f} seconds\")\n",
    "    print(f\"Best test accuracy: {best_test_acc:.2f}%\")\n",
    "\n",
    "    # Test discrete inference (switch to hard logic gates)\n",
    "    print(\"\\nTesting discrete inference...\")\n",
    "    model.eval()  # This switches to discrete/hard logic mode\n",
    "\n",
    "    start_time = time.time()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    inference_time = time.time() - start_time\n",
    "    inference_speed = inference_time / total\n",
    "\n",
    "    print(f\"Discrete inference accuracy: {100. * correct / total:.2f}%\")\n",
    "    print(f\"Inference speed: {inference_speed:.6f} seconds per sample\")\n",
    "\n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), 'final_logic_conv_difflogic_mnist.pth')\n",
    "\n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LOGIC GATE CONVOLUTIONAL DIFFLOGIC MNIST RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Architecture: Custom logic gate convolutions + DiffLogic FC layers\")\n",
    "    print(f\"Base kernel count (k): {k}\")\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"Training epochs: {num_epochs}\")\n",
    "    print(f\"Best test accuracy: {best_test_acc:.2f}%\")\n",
    "    print(f\"Final test accuracy: {test_accuracies[-1]:.2f}%\")\n",
    "    print(f\"Inference speed: {inference_speed:.6f} seconds per sample\")\n",
    "    print()\n",
    "    print(\"Logic gate convolutions replace traditional conv layers with:\")\n",
    "    print(\"- 16 different logic gates (AND, OR, XOR, NOT, etc.)\")\n",
    "    print(\"- Tree-structured logic processing with configurable depth\")\n",
    "    print(\"- Soft logic during training, hard logic during inference\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c039dae8-69c1-4ec1-90de-796d31213df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Base kernel count k = 16\n",
      "Training samples: 60000\n",
      "Test samples: 10000\n",
      "Model created with 596736 parameters\n",
      "\n",
      "================================================================================\n",
      "LOGIC GATE CONVOLUTIONAL DIFFLOGIC MNIST\n",
      "================================================================================\n",
      "Input: 1 × 28 × 28\n",
      "Conv1: 16 logic gate filters, 5×5, depth=3, no padding -> 16 × 24 × 24\n",
      "Pool1: OR pooling 2×2, stride 2 -> 16 × 12 × 12\n",
      "Conv2: 48 logic gate filters, 3×3, depth=3 -> 48 × 12 × 12\n",
      "Pool2: OR pooling 2×2, stride 2 -> 48 × 6 × 6\n",
      "Conv3: 144 logic gate filters, 3×3, depth=3 -> 144 × 6 × 6\n",
      "Pool3: OR pooling 2×2, stride 2 -> 144 × 3 × 3\n",
      "Flatten: -> 1296\n",
      "FC1: Regular differentiable logic layer 1296 -> 20480\n",
      "FC2: Regular differentiable logic layer 20480 -> 10240\n",
      "FC3: Regular differentiable logic layer 10240 -> 5120\n",
      "GroupSum: 5120 -> 10 classes\n",
      "================================================================================\n",
      "Loaded best model checkpoint from best_logic_conv_difflogic_mnist.pth\n",
      "Loaded model accuracy: 13.09%\n",
      "Starting training with logic gate convolutions...\n",
      "\n",
      "Epoch 1/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=1.5881, Acc=62.49%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.50it/s, Acc=82.02%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 82.02%\n",
      "Train Loss: 1.5881, Train Acc: 62.49%\n",
      "Test Loss: 0.9703, Test Acc: 82.02%\n",
      "\n",
      "Epoch 2/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.8845, Acc=82.77%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.60it/s, Acc=85.72%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 85.72%\n",
      "Train Loss: 0.8845, Train Acc: 82.77%\n",
      "Test Loss: 0.7682, Test Acc: 85.72%\n",
      "\n",
      "Epoch 3/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.7575, Acc=85.09%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.54it/s, Acc=87.28%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 87.28%\n",
      "Train Loss: 0.7575, Train Acc: 85.09%\n",
      "Test Loss: 0.6980, Test Acc: 87.28%\n",
      "\n",
      "Epoch 4/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.7055, Acc=85.83%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.57it/s, Acc=87.55%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 87.55%\n",
      "Train Loss: 0.7055, Train Acc: 85.83%\n",
      "Test Loss: 0.6662, Test Acc: 87.55%\n",
      "\n",
      "Epoch 5/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.6776, Acc=86.38%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.60it/s, Acc=87.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 87.71%\n",
      "Train Loss: 0.6776, Train Acc: 86.38%\n",
      "Test Loss: 0.6449, Test Acc: 87.71%\n",
      "\n",
      "Epoch 6/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.6559, Acc=86.75%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.46it/s, Acc=88.42%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 88.42%\n",
      "Train Loss: 0.6559, Train Acc: 86.75%\n",
      "Test Loss: 0.6290, Test Acc: 88.42%\n",
      "\n",
      "Epoch 7/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.6405, Acc=87.12%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.55it/s, Acc=88.45%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 88.45%\n",
      "Train Loss: 0.6405, Train Acc: 87.12%\n",
      "Test Loss: 0.6160, Test Acc: 88.45%\n",
      "\n",
      "Epoch 8/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.6284, Acc=87.36%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.56it/s, Acc=88.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 88.88%\n",
      "Train Loss: 0.6284, Train Acc: 87.36%\n",
      "Test Loss: 0.6041, Test Acc: 88.88%\n",
      "\n",
      "Epoch 9/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.6180, Acc=87.65%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.56it/s, Acc=89.01%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 89.01%\n",
      "Train Loss: 0.6180, Train Acc: 87.65%\n",
      "Test Loss: 0.5964, Test Acc: 89.01%\n",
      "\n",
      "Epoch 10/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.6100, Acc=87.80%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.60it/s, Acc=89.04%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 89.04%\n",
      "Train Loss: 0.6100, Train Acc: 87.80%\n",
      "Test Loss: 0.5905, Test Acc: 89.04%\n",
      "\n",
      "Epoch 11/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.6036, Acc=87.99%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.58it/s, Acc=89.20%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 89.20%\n",
      "Train Loss: 0.6036, Train Acc: 87.99%\n",
      "Test Loss: 0.5852, Test Acc: 89.20%\n",
      "\n",
      "Epoch 12/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5966, Acc=88.25%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.57it/s, Acc=89.24%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 89.24%\n",
      "Train Loss: 0.5966, Train Acc: 88.25%\n",
      "Test Loss: 0.5785, Test Acc: 89.24%\n",
      "\n",
      "Epoch 13/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5908, Acc=88.39%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.55it/s, Acc=89.29%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 89.29%\n",
      "Train Loss: 0.5908, Train Acc: 88.39%\n",
      "Test Loss: 0.5739, Test Acc: 89.29%\n",
      "\n",
      "Epoch 14/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5851, Acc=88.44%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.49it/s, Acc=89.39%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 89.39%\n",
      "Train Loss: 0.5851, Train Acc: 88.44%\n",
      "Test Loss: 0.5671, Test Acc: 89.39%\n",
      "\n",
      "Epoch 15/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5791, Acc=88.57%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.57it/s, Acc=89.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 89.54%\n",
      "Train Loss: 0.5791, Train Acc: 88.57%\n",
      "Test Loss: 0.5626, Test Acc: 89.54%\n",
      "\n",
      "Epoch 16/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5750, Acc=88.68%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.62it/s, Acc=89.61%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 89.61%\n",
      "Train Loss: 0.5750, Train Acc: 88.68%\n",
      "Test Loss: 0.5586, Test Acc: 89.61%\n",
      "\n",
      "Epoch 17/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5714, Acc=88.73%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.52it/s, Acc=89.73%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 89.73%\n",
      "Train Loss: 0.5714, Train Acc: 88.73%\n",
      "Test Loss: 0.5554, Test Acc: 89.73%\n",
      "\n",
      "Epoch 18/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5685, Acc=88.78%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.56it/s, Acc=89.80%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 89.80%\n",
      "Train Loss: 0.5685, Train Acc: 88.78%\n",
      "Test Loss: 0.5528, Test Acc: 89.80%\n",
      "\n",
      "Epoch 19/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.54it/s, Loss=0.5645, Acc=88.94%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.57it/s, Acc=89.90%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 89.90%\n",
      "Train Loss: 0.5645, Train Acc: 88.94%\n",
      "Test Loss: 0.5484, Test Acc: 89.90%\n",
      "\n",
      "Epoch 20/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5614, Acc=89.03%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.46it/s, Acc=90.07%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 90.07%\n",
      "Train Loss: 0.5614, Train Acc: 89.03%\n",
      "Test Loss: 0.5453, Test Acc: 90.07%\n",
      "\n",
      "Epoch 21/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5578, Acc=89.10%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.59it/s, Acc=89.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5578, Train Acc: 89.10%\n",
      "Test Loss: 0.5418, Test Acc: 89.93%\n",
      "\n",
      "Epoch 22/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5545, Acc=89.22%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.51it/s, Acc=90.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5545, Train Acc: 89.22%\n",
      "Test Loss: 0.5383, Test Acc: 90.00%\n",
      "\n",
      "Epoch 23/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5507, Acc=89.30%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.53it/s, Acc=90.33%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 90.33%\n",
      "Train Loss: 0.5507, Train Acc: 89.30%\n",
      "Test Loss: 0.5328, Test Acc: 90.33%\n",
      "\n",
      "Epoch 24/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5468, Acc=89.40%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.58it/s, Acc=90.28%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5468, Train Acc: 89.40%\n",
      "Test Loss: 0.5306, Test Acc: 90.28%\n",
      "\n",
      "Epoch 25/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5444, Acc=89.42%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.55it/s, Acc=90.38%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 90.38%\n",
      "Train Loss: 0.5444, Train Acc: 89.42%\n",
      "Test Loss: 0.5282, Test Acc: 90.38%\n",
      "\n",
      "Epoch 26/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5419, Acc=89.48%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.55it/s, Acc=90.44%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 90.44%\n",
      "Train Loss: 0.5419, Train Acc: 89.48%\n",
      "Test Loss: 0.5263, Test Acc: 90.44%\n",
      "\n",
      "Epoch 27/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5399, Acc=89.52%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.42it/s, Acc=90.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5399, Train Acc: 89.52%\n",
      "Test Loss: 0.5244, Test Acc: 90.31%\n",
      "\n",
      "Epoch 28/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5386, Acc=89.53%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.40it/s, Acc=90.46%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 90.46%\n",
      "Train Loss: 0.5386, Train Acc: 89.53%\n",
      "Test Loss: 0.5236, Test Acc: 90.46%\n",
      "\n",
      "Epoch 29/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5373, Acc=89.59%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.39it/s, Acc=90.49%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 90.49%\n",
      "Train Loss: 0.5373, Train Acc: 89.59%\n",
      "Test Loss: 0.5226, Test Acc: 90.49%\n",
      "\n",
      "Epoch 30/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5358, Acc=89.61%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.56it/s, Acc=90.57%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 90.57%\n",
      "Train Loss: 0.5358, Train Acc: 89.61%\n",
      "Test Loss: 0.5207, Test Acc: 90.57%\n",
      "\n",
      "Epoch 31/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5345, Acc=89.61%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.57it/s, Acc=90.69%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 90.69%\n",
      "Train Loss: 0.5345, Train Acc: 89.61%\n",
      "Test Loss: 0.5197, Test Acc: 90.69%\n",
      "\n",
      "Epoch 32/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5332, Acc=89.64%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.42it/s, Acc=90.73%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 90.73%\n",
      "Train Loss: 0.5332, Train Acc: 89.64%\n",
      "Test Loss: 0.5193, Test Acc: 90.73%\n",
      "\n",
      "Epoch 33/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5323, Acc=89.66%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.47it/s, Acc=90.78%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 90.78%\n",
      "Train Loss: 0.5323, Train Acc: 89.66%\n",
      "Test Loss: 0.5181, Test Acc: 90.78%\n",
      "\n",
      "Epoch 34/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5314, Acc=89.67%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.45it/s, Acc=90.73%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5314, Train Acc: 89.67%\n",
      "Test Loss: 0.5173, Test Acc: 90.73%\n",
      "\n",
      "Epoch 35/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5300, Acc=89.71%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.40it/s, Acc=90.67%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5300, Train Acc: 89.71%\n",
      "Test Loss: 0.5156, Test Acc: 90.67%\n",
      "\n",
      "Epoch 36/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5261, Acc=89.78%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.46it/s, Acc=90.62%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5261, Train Acc: 89.78%\n",
      "Test Loss: 0.5120, Test Acc: 90.62%\n",
      "\n",
      "Epoch 37/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5245, Acc=89.78%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.42it/s, Acc=90.66%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5245, Train Acc: 89.78%\n",
      "Test Loss: 0.5107, Test Acc: 90.66%\n",
      "\n",
      "Epoch 38/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5237, Acc=89.83%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.42it/s, Acc=90.72%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5237, Train Acc: 89.83%\n",
      "Test Loss: 0.5099, Test Acc: 90.72%\n",
      "\n",
      "Epoch 39/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5231, Acc=89.80%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.42it/s, Acc=90.73%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5231, Train Acc: 89.80%\n",
      "Test Loss: 0.5096, Test Acc: 90.73%\n",
      "\n",
      "Epoch 40/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5223, Acc=89.85%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.42it/s, Acc=90.74%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5223, Train Acc: 89.85%\n",
      "Test Loss: 0.5086, Test Acc: 90.74%\n",
      "\n",
      "Epoch 41/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5217, Acc=89.85%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.53it/s, Acc=90.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5217, Train Acc: 89.85%\n",
      "Test Loss: 0.5081, Test Acc: 90.71%\n",
      "\n",
      "Epoch 42/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5208, Acc=89.86%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.45it/s, Acc=90.77%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5208, Train Acc: 89.86%\n",
      "Test Loss: 0.5073, Test Acc: 90.77%\n",
      "\n",
      "Epoch 43/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.51it/s, Loss=0.5201, Acc=89.89%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.40it/s, Acc=90.76%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5201, Train Acc: 89.89%\n",
      "Test Loss: 0.5063, Test Acc: 90.76%\n",
      "\n",
      "Epoch 44/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5192, Acc=89.98%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.55it/s, Acc=90.78%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5192, Train Acc: 89.98%\n",
      "Test Loss: 0.5055, Test Acc: 90.78%\n",
      "\n",
      "Epoch 45/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5181, Acc=89.96%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.54it/s, Acc=90.87%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 90.87%\n",
      "Train Loss: 0.5181, Train Acc: 89.96%\n",
      "Test Loss: 0.5040, Test Acc: 90.87%\n",
      "\n",
      "Epoch 46/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5172, Acc=89.97%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.43it/s, Acc=90.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 90.88%\n",
      "Train Loss: 0.5172, Train Acc: 89.97%\n",
      "Test Loss: 0.5034, Test Acc: 90.88%\n",
      "\n",
      "Epoch 47/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.51it/s, Loss=0.5168, Acc=89.96%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.39it/s, Acc=90.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5168, Train Acc: 89.96%\n",
      "Test Loss: 0.5030, Test Acc: 90.82%\n",
      "\n",
      "Epoch 48/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.51it/s, Loss=0.5162, Acc=89.98%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.44it/s, Acc=90.84%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5162, Train Acc: 89.98%\n",
      "Test Loss: 0.5027, Test Acc: 90.84%\n",
      "\n",
      "Epoch 49/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5156, Acc=89.94%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.42it/s, Acc=90.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5156, Train Acc: 89.94%\n",
      "Test Loss: 0.5014, Test Acc: 90.86%\n",
      "\n",
      "Epoch 50/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.51it/s, Loss=0.5146, Acc=89.97%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.38it/s, Acc=90.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5146, Train Acc: 89.97%\n",
      "Test Loss: 0.5008, Test Acc: 90.86%\n",
      "\n",
      "Epoch 51/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5138, Acc=89.98%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.56it/s, Acc=90.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5138, Train Acc: 89.98%\n",
      "Test Loss: 0.4997, Test Acc: 90.86%\n",
      "\n",
      "Epoch 52/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5132, Acc=89.97%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.51it/s, Acc=90.89%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 90.89%\n",
      "Train Loss: 0.5132, Train Acc: 89.97%\n",
      "Test Loss: 0.4990, Test Acc: 90.89%\n",
      "\n",
      "Epoch 53/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5128, Acc=89.99%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.56it/s, Acc=90.84%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5128, Train Acc: 89.99%\n",
      "Test Loss: 0.4986, Test Acc: 90.84%\n",
      "\n",
      "Epoch 54/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5125, Acc=89.98%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.59it/s, Acc=90.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5125, Train Acc: 89.98%\n",
      "Test Loss: 0.4984, Test Acc: 90.86%\n",
      "\n",
      "Epoch 55/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5121, Acc=89.99%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.40it/s, Acc=90.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5121, Train Acc: 89.99%\n",
      "Test Loss: 0.4977, Test Acc: 90.82%\n",
      "\n",
      "Epoch 56/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5117, Acc=89.97%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.48it/s, Acc=90.92%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 90.92%\n",
      "Train Loss: 0.5117, Train Acc: 89.97%\n",
      "Test Loss: 0.4972, Test Acc: 90.92%\n",
      "\n",
      "Epoch 57/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.51it/s, Loss=0.5113, Acc=89.99%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.46it/s, Acc=90.92%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5113, Train Acc: 89.99%\n",
      "Test Loss: 0.4971, Test Acc: 90.92%\n",
      "\n",
      "Epoch 58/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5110, Acc=90.01%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.61it/s, Acc=90.97%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 90.97%\n",
      "Train Loss: 0.5110, Train Acc: 90.01%\n",
      "Test Loss: 0.4962, Test Acc: 90.97%\n",
      "\n",
      "Epoch 59/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5103, Acc=89.98%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.58it/s, Acc=90.91%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5103, Train Acc: 89.98%\n",
      "Test Loss: 0.4954, Test Acc: 90.91%\n",
      "\n",
      "Epoch 60/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5094, Acc=90.03%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.60it/s, Acc=90.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5094, Train Acc: 90.03%\n",
      "Test Loss: 0.4950, Test Acc: 90.93%\n",
      "\n",
      "Epoch 61/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5080, Acc=90.07%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.56it/s, Acc=90.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5080, Train Acc: 90.07%\n",
      "Test Loss: 0.4938, Test Acc: 90.93%\n",
      "\n",
      "Epoch 62/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5075, Acc=90.09%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.60it/s, Acc=90.96%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5075, Train Acc: 90.09%\n",
      "Test Loss: 0.4933, Test Acc: 90.96%\n",
      "\n",
      "Epoch 63/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5072, Acc=90.08%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.60it/s, Acc=90.97%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5072, Train Acc: 90.08%\n",
      "Test Loss: 0.4931, Test Acc: 90.97%\n",
      "\n",
      "Epoch 64/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5068, Acc=90.08%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.54it/s, Acc=90.95%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5068, Train Acc: 90.08%\n",
      "Test Loss: 0.4926, Test Acc: 90.95%\n",
      "\n",
      "Epoch 65/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5064, Acc=90.09%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.56it/s, Acc=90.91%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5064, Train Acc: 90.09%\n",
      "Test Loss: 0.4921, Test Acc: 90.91%\n",
      "\n",
      "Epoch 66/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.53it/s, Loss=0.5059, Acc=90.11%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.61it/s, Acc=90.94%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5059, Train Acc: 90.11%\n",
      "Test Loss: 0.4918, Test Acc: 90.94%\n",
      "\n",
      "Epoch 67/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.51it/s, Loss=0.5053, Acc=90.14%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.45it/s, Acc=90.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5053, Train Acc: 90.14%\n",
      "Test Loss: 0.4911, Test Acc: 90.86%\n",
      "\n",
      "Epoch 68/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.52it/s, Loss=0.5048, Acc=90.14%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.45it/s, Acc=91.01%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Test accuracy: 91.01%\n",
      "Train Loss: 0.5048, Train Acc: 90.14%\n",
      "Test Loss: 0.4908, Test Acc: 91.01%\n",
      "\n",
      "Epoch 69/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.51it/s, Loss=0.5046, Acc=90.14%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.41it/s, Acc=90.95%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5046, Train Acc: 90.14%\n",
      "Test Loss: 0.4906, Test Acc: 90.95%\n",
      "\n",
      "Epoch 70/70\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 600/600 [02:12<00:00,  4.51it/s, Loss=0.5043, Acc=90.15%]\n",
      "Testing: 100%|██████████| 100/100 [00:04<00:00, 24.45it/s, Acc=90.95%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5043, Train Acc: 90.15%\n",
      "Test Loss: 0.4904, Test Acc: 90.95%\n",
      "\n",
      "Training completed in 9568.44 seconds\n",
      "Best test accuracy: 91.01%\n",
      "\n",
      "Testing discrete inference with BEST model...\n",
      "Discrete inference accuracy: 91.01%\n",
      "Inference speed: 0.000403 seconds per sample\n",
      "\n",
      "================================================================================\n",
      "LOGIC GATE CONVOLUTIONAL DIFFLOGIC MNIST RESULTS\n",
      "================================================================================\n",
      "Architecture: Custom logic gate convolutions + DiffLogic FC layers\n",
      "Base kernel count (k): 16\n",
      "Total parameters: 596,736\n",
      "Training epochs: 70\n",
      "Best test accuracy: 91.01%\n",
      "Inference speed: 0.000403 seconds per sample\n",
      "\n",
      "Logic gate convolutions replace traditional conv layers with:\n",
      "- 16 different logic gates (AND, OR, XOR, NOT, etc.)\n",
      "- Tree-structured logic processing with configurable depth\n",
      "- Soft logic during training, hard logic during inference\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Retraining\n",
    "# Type definitions\n",
    "InitializationType = Literal['residual', 'random']\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "total_epochs = 70  # That's make 100 total epochs\n",
    "k = 16  # Base number of kernels\n",
    "\n",
    "print(f\"Base kernel count k = {k}\")\n",
    "\n",
    "# Data loading and preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Logic gate definitions\n",
    "logic_gates = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "\n",
    "def apply_logic_gate(a: torch.Tensor, b: torch.Tensor, logic_gate: int):\n",
    "    return {\n",
    "        0:  torch.zeros_like(a),\n",
    "        1:  a * b,\n",
    "        2:  a - a * b,\n",
    "        3:  a,\n",
    "        4:  b - a * b,\n",
    "        5:  b,\n",
    "        6:  a + b - 2 * a * b,\n",
    "        7:  a + b - a * b,\n",
    "        8:  1 - (a + b - a * b),\n",
    "        9:  1 - (a + b - 2 * a * b),\n",
    "        10: 1 - b,\n",
    "        11: 1 - b + a * b,\n",
    "        12: 1 - a,\n",
    "        13: 1 - a + a * b,\n",
    "        14: 1 - a * b,\n",
    "        15: torch.ones_like(a),\n",
    "    }[logic_gate]\n",
    "\n",
    "class Logic(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim: int,\n",
    "                 out_dim: int,\n",
    "                 initialization_type: InitializationType = 'residual',\n",
    "                 device=None\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.initialization_type = initialization_type\n",
    "        self.device = device or torch.device('cpu')\n",
    "        \n",
    "        a, b = self.get_connections()\n",
    "        self.register_buffer('a', a)\n",
    "        self.register_buffer('b', b)\n",
    "        \n",
    "        weights = torch.randn(out_dim, len(logic_gates), device=self.device)\n",
    "        if self.initialization_type == 'residual':\n",
    "            weights[:, :] = 0\n",
    "            weights[:, 3] = 5  # Initialize to identity gate\n",
    "        self.weights = torch.nn.parameter.Parameter(weights)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        a, b = x[:, self.a, ...], x[:, self.b, ...]\n",
    "        \n",
    "        if self.training:\n",
    "            normalized_weights = torch.nn.functional.softmax(self.weights, dim=-1).to(x.dtype).to(self.device)\n",
    "            r = torch.zeros_like(a).to(x.dtype).to(self.device)\n",
    "            for logic_gate in logic_gates:\n",
    "                if len(a.shape) > 2:\n",
    "                    nw = einops.repeat(normalized_weights[..., logic_gate], 'weights -> weights depth', depth=a.shape[-1])\n",
    "                else:\n",
    "                    nw = normalized_weights[..., logic_gate]\n",
    "                r = r + nw * apply_logic_gate(a, b, logic_gate)\n",
    "            return r\n",
    "        else:\n",
    "            one_hot_weights = torch.nn.functional.one_hot(self.weights.argmax(-1), len(logic_gates)).to(torch.float32).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                r = torch.zeros_like(a).to(x.dtype).to(self.device)\n",
    "                for logic_gate in logic_gates:\n",
    "                    if len(a.shape) > 2:\n",
    "                        ohw = einops.repeat(one_hot_weights[..., logic_gate], 'weights -> weights depth', depth=a.shape[-1])\n",
    "                    else:\n",
    "                        ohw = one_hot_weights[..., logic_gate]\n",
    "                    r = r + ohw * apply_logic_gate(a, b, logic_gate)\n",
    "                return r\n",
    "\n",
    "    def get_connections(self):\n",
    "        connections = torch.randperm(2 * self.out_dim) % self.in_dim\n",
    "        connections = torch.randperm(self.in_dim)[connections]\n",
    "        connections = connections.reshape(2, self.out_dim)\n",
    "        a, b = connections[0], connections[1]\n",
    "        a, b = a.to(torch.int64), b.to(torch.int64)\n",
    "        a, b = a.to(self.device), b.to(self.device)\n",
    "        return a, b\n",
    "\n",
    "class LogicTree(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim: int,\n",
    "                 depth: int = 3,\n",
    "                 initialization_type: InitializationType = 'residual',\n",
    "                 device=None,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.device = device or torch.device('cpu')\n",
    "        \n",
    "        layers = [LogicLayer(in_dim, int(2 ** (depth - 1)), initialization_type=initialization_type, device=self.device,implementation='cuda' if device.type == 'cuda' else 'python',\n",
    "                    connections='random',grad_factor=1.5 )]\n",
    "        for i in range(0, depth - 1, 1):\n",
    "            layers.append(LogicLayer(int(2 ** (depth - 1 - i)), int(2 ** (depth - 1 - i - 1)), \n",
    "                            initialization_type=initialization_type, device=self.device,implementation='cuda' if device.type == 'cuda' else 'python',\n",
    "                            connections='random',grad_factor=1.5))\n",
    "        \n",
    "        self.tree = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.tree(x)\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 depth: int = 3,\n",
    "                 kernel_size: int = 3,\n",
    "                 stride: int = 1,\n",
    "                 padding: int = 1,\n",
    "                 initialization_type: InitializationType = 'residual',\n",
    "                 device=None\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.device = device or torch.device('cpu')\n",
    "        \n",
    "        self.filters = nn.ModuleList([\n",
    "            LogicTree(in_dim=kernel_size ** 2 * in_channels, depth=depth, \n",
    "                     initialization_type=initialization_type, device=self.device) \n",
    "            for _ in range(out_channels)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, _, height, width = x.shape\n",
    "        x = F.pad(x, (self.padding, self.padding, self.padding, self.padding), mode='constant', value=0)\n",
    "        out_height = (height + 2 * self.padding - self.kernel_size) // self.stride + 1\n",
    "        out_width = (width + 2 * self.padding - self.kernel_size) // self.stride + 1\n",
    "        patches = F.unfold(x, kernel_size=self.kernel_size, stride=self.stride)\n",
    "        outputs = []\n",
    "        \n",
    "        patches = einops.rearrange(patches, 'b h w -> (b w) h', h=patches.shape[1], w=patches.shape[2]) # Input is (100,25,576) Output: (57600,25)\n",
    "        for filter in self.filters:\n",
    "            out = filter(patches)  # Shape: (batch_size, 1, out_height * out_width)\n",
    "            out = einops.rearrange(out, '(b h w) 1 -> b (h w)', h=out_height, w=out_width)\n",
    "            outputs.append(out)\n",
    "        \n",
    "        output_tensor = torch.stack(outputs, dim=1)  # Shape: (batch_size, out_channels, out_height * out_width)\n",
    "        output_tensor = einops.rearrange(output_tensor, 'b c (h w) -> b c h w', h=out_height, w=out_width)\n",
    "        return output_tensor\n",
    "\n",
    "class CustomOrPool2d(nn.Module):\n",
    "    def __init__(self, kernel_size=2, stride=2, padding=0):\n",
    "        super(CustomOrPool2d, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Use MaxPool2d as approximation to OR pooling\n",
    "        # In binary logic, max operation approximates OR\n",
    "        return torch.max_pool2d(x, self.kernel_size, self.stride, self.padding)\n",
    "\n",
    "class ConvDiffLogicMNIST(nn.Module):\n",
    "    def __init__(self, k=16):\n",
    "        super(ConvDiffLogicMNIST, self).__init__()\n",
    "        self.k = k\n",
    "        \n",
    "        # Convolutional block 1: k kernels, 5x5, depth=3, no padding\n",
    "        # Input: 1 × 28 × 28 -> Output: k × 24 × 24 (28-5+1=24)\n",
    "        self.conv1 = Conv(in_channels=1, out_channels=k, kernel_size=5, depth=3, \n",
    "                         padding=0, initialization_type='residual', device=device)\n",
    "        \n",
    "        # OR pooling 1: 2x2, stride 2\n",
    "        # k × 24 × 24 -> k × 12 × 12\n",
    "        self.pool1 = CustomOrPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Convolutional block 2: 3*k kernels, 3x3, depth=3\n",
    "        # k × 12 × 12 -> 3*k × 12 × 12 (with padding=1), then pooled to 3*k × 6 × 6\n",
    "        self.conv2 = Conv(in_channels=k, out_channels=3*k, kernel_size=3, depth=3, \n",
    "                         padding=1, initialization_type='residual', device=device)\n",
    "        \n",
    "        # OR pooling 2: 2x2, stride 2\n",
    "        # 3*k × 12 × 12 -> 3*k × 6 × 6\n",
    "        self.pool2 = CustomOrPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Convolutional block 3: 9*k kernels, 3x3, depth=3\n",
    "        # 3*k × 6 × 6 -> 9*k × 6 × 6 (with padding=1), then pooled to 9*k × 3 × 3\n",
    "        self.conv3 = Conv(in_channels=3*k, out_channels=9*k, kernel_size=3, depth=3, \n",
    "                         padding=1, initialization_type='residual', device=device)\n",
    "        \n",
    "        # OR pooling 3: 2x2, stride 2\n",
    "        # 9*k × 6 × 6 -> 9*k × 3 × 3\n",
    "        self.pool3 = CustomOrPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Flatten: 9*k × 3 × 3 -> 81*k\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Regular differentiable logic layers (as specified in paper)\n",
    "        # 81*k → 1280*k\n",
    "        self.fc1 = LogicLayer(\n",
    "            in_dim=81*k,\n",
    "            out_dim=1280*k,\n",
    "            device=device,\n",
    "            implementation='cuda' if device.type == 'cuda' else 'python',\n",
    "            connections='random',\n",
    "            grad_factor=1.5 , # Higher for deeper networks\n",
    "        )\n",
    "        \n",
    "        # 1280*k → 640*k\n",
    "        self.fc2 = LogicLayer(\n",
    "            in_dim=1280*k,\n",
    "            out_dim=640*k,\n",
    "            device=device,\n",
    "            implementation='cuda' if device.type == 'cuda' else 'python',\n",
    "            connections='random',\n",
    "            grad_factor=1.5\n",
    "        )\n",
    "        \n",
    "        # 640*k → 320*k\n",
    "        self.fc3 = LogicLayer(\n",
    "            in_dim=640*k,\n",
    "            out_dim=320*k,\n",
    "            device=device,\n",
    "            implementation='cuda' if device.type == 'cuda' else 'python',\n",
    "            connections='random',\n",
    "            grad_factor=1.5\n",
    "        )\n",
    "        \n",
    "        # GroupSum: 320*k → 10 (10 classes)\n",
    "        # Using tau=30 as in the paper specifications\n",
    "        self.group_sum = GroupSum(k=10, tau=30)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input thresholding for binary processing (as mentioned in paper)\n",
    "        # The paper mentions using binary inputs\n",
    "        x = (x > 0.5).float()\n",
    "        \n",
    "        # Debug shape printing (uncomment for debugging)\n",
    "        # print(f\"Input shape: {x.shape}\")\n",
    "        \n",
    "        # Convolutional processing with logic gates\n",
    "        x = self.conv1(x)\n",
    "        # print(f\"After conv1: {x.shape}\")\n",
    "        \n",
    "        x = self.pool1(x)\n",
    "        # print(f\"After pool1: {x.shape}\")\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        # print(f\"After conv2: {x.shape}\")\n",
    "        \n",
    "        x = self.pool2(x)\n",
    "        # print(f\"After pool2: {x.shape}\")\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        # print(f\"After conv3: {x.shape}\")\n",
    "        \n",
    "        x = self.pool3(x)\n",
    "        # print(f\"After pool3: {x.shape}\")\n",
    "        \n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "        # print(f\"After flatten: {x.shape}\")\n",
    "        \n",
    "        # Fully connected logic layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # GroupSum for classification\n",
    "        x = self.group_sum(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = ConvDiffLogicMNIST(k=k).to(device)\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "\n",
    "# Print architecture details\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOGIC GATE CONVOLUTIONAL DIFFLOGIC MNIST\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Input: 1 × 28 × 28\")\n",
    "print(f\"Conv1: {k} logic gate filters, 5×5, depth=3, no padding -> {k} × 24 × 24\")\n",
    "print(f\"Pool1: OR pooling 2×2, stride 2 -> {k} × 12 × 12\")\n",
    "print(f\"Conv2: {3*k} logic gate filters, 3×3, depth=3 -> {3*k} × 12 × 12\")\n",
    "print(f\"Pool2: OR pooling 2×2, stride 2 -> {3*k} × 6 × 6\")\n",
    "print(f\"Conv3: {9*k} logic gate filters, 3×3, depth=3 -> {9*k} × 6 × 6\")\n",
    "print(f\"Pool3: OR pooling 2×2, stride 2 -> {9*k} × 3 × 3\")\n",
    "print(f\"Flatten: -> {81*k}\")\n",
    "print(f\"FC1: Regular differentiable logic layer {81*k} -> {1280*k}\")\n",
    "print(f\"FC2: Regular differentiable logic layer {1280*k} -> {640*k}\")\n",
    "print(f\"FC3: Regular differentiable logic layer {640*k} -> {320*k}\")\n",
    "print(f\"GroupSum: {320*k} -> 10 classes\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_path = 'best_logic_conv_difflogic_mnist.pth'\n",
    "current_best_acc = 0.0\n",
    "\n",
    "# Load checkpoint if exists\n",
    "if os.path.exists(model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(f\"Loaded best model checkpoint from {model_path}\")\n",
    "    \n",
    "    # Evaluate the loaded model to get current best accuracy\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "        \n",
    "        current_best_acc = 100. * correct / total\n",
    "        print(f\"Loaded model accuracy: {current_best_acc:.2f}%\")\n",
    "\n",
    "# Initialize optimizer AFTER potential model loading\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc='Training')\n",
    "    for batch_idx, (data, target) in enumerate(progress_bar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
    "            'Acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    return running_loss / len(train_loader), 100. * correct / total\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(test_loader, desc='Testing')\n",
    "        for data, target in progress_bar:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'Acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    return test_loss / len(test_loader), 100. * correct / total\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Starting training with logic gate convolutions...\")\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(0, total_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{total_epochs}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        \n",
    "        # Evaluate\n",
    "        test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        # Save best model\n",
    "        if test_acc > current_best_acc:\n",
    "            current_best_acc = test_acc\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"New best model saved! Test accuracy: {test_acc:.2f}%\")\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {total_time:.2f} seconds\")\n",
    "    print(f\"Best test accuracy: {current_best_acc:.2f}%\")\n",
    "\n",
    "    # Test discrete inference with best model\n",
    "    print(\"\\nTesting discrete inference with BEST model...\")\n",
    "    model.load_state_dict(torch.load(model_path))  # Load best model\n",
    "    model.eval()  # This switches to discrete/hard logic mode\n",
    "\n",
    "    start_time = time.time()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    inference_time = time.time() - start_time\n",
    "    inference_speed = inference_time / total\n",
    "\n",
    "    print(f\"Discrete inference accuracy: {100. * correct / total:.2f}%\")\n",
    "    print(f\"Inference speed: {inference_speed:.6f} seconds per sample\")\n",
    "\n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), 'final_logic_conv_difflogic_mnist.pth')\n",
    "\n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LOGIC GATE CONVOLUTIONAL DIFFLOGIC MNIST RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Architecture: Custom logic gate convolutions + DiffLogic FC layers\")\n",
    "    print(f\"Base kernel count (k): {k}\")\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"Training epochs: {total_epochs}\")\n",
    "    print(f\"Best test accuracy: {current_best_acc:.2f}%\")\n",
    "    print(f\"Inference speed: {inference_speed:.6f} seconds per sample\")\n",
    "    print()\n",
    "    print(\"Logic gate convolutions replace traditional conv layers with:\")\n",
    "    print(\"- 16 different logic gates (AND, OR, XOR, NOT, etc.)\")\n",
    "    print(\"- Tree-structured logic processing with configurable depth\")\n",
    "    print(\"- Soft logic during training, hard logic during inference\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac3ed976-4d04-4e8a-88d7-d60ec4da7aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Base kernel count k = 16\n",
      "Expected shapes from paper:\n",
      "After conv1 + pool1: 16 × 12 × 12\n",
      "After conv2 + pool2: 48 × 6 × 6\n",
      "After conv3 + pool3: 144 × 3 × 3\n",
      "After flattening: 1296\n",
      "Training samples: 50000\n",
      "Validation samples: 10000\n",
      "Test samples: 10000\n",
      "Model created with 596736 parameters\n",
      "\n",
      "================================================================================\n",
      "LOGIC GATE CONVOLUTIONAL DIFFLOGIC MNIST\n",
      "================================================================================\n",
      "Input: 1 × 28 × 28\n",
      "Conv1: 16 logic gate filters, 5×5, depth=3, no padding -> 16 × 24 × 24\n",
      "Pool1: OR pooling 2×2, stride 2 -> 16 × 12 × 12\n",
      "Conv2: 48 logic gate filters, 3×3, depth=3 -> 48 × 12 × 12\n",
      "Pool2: OR pooling 2×2, stride 2 -> 48 × 6 × 6\n",
      "Conv3: 144 logic gate filters, 3×3, depth=3 -> 144 × 6 × 6\n",
      "Pool3: OR pooling 2×2, stride 2 -> 144 × 3 × 3\n",
      "Flatten: -> 1296\n",
      "FC1: Regular differentiable logic layer 1296 -> 20480\n",
      "FC2: Regular differentiable logic layer 20480 -> 10240\n",
      "FC3: Regular differentiable logic layer 10240 -> 5120\n",
      "GroupSum: 5120 -> 10 classes\n",
      "================================================================================\n",
      "Starting training with logic gate convolutions...\n",
      "\n",
      "Epoch 1/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:57<00:00,  3.44it/s, Loss=1.7863, Acc=55.38%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.52it/s, Acc=30.42%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.40it/s, Acc=30.64%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7863, Train Acc: 55.38%\n",
      "Val Loss: 2.0326, Val Acc: 30.64%\n",
      "Test Loss: 2.0275, Test Acc: 30.42%\n",
      "\n",
      "Epoch 2/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:57<00:00,  3.44it/s, Loss=0.9933, Acc=72.98%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.46it/s, Acc=77.75%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.43it/s, Acc=76.55%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9933, Train Acc: 72.98%\n",
      "Val Loss: 0.8033, Val Acc: 76.55%\n",
      "Test Loss: 0.7755, Test Acc: 77.75%\n",
      "\n",
      "Epoch 3/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:57<00:00,  3.44it/s, Loss=0.7217, Acc=80.25%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.48it/s, Acc=83.24%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.39it/s, Acc=81.98%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7217, Train Acc: 80.25%\n",
      "Val Loss: 0.6245, Val Acc: 81.98%\n",
      "Test Loss: 0.5927, Test Acc: 83.24%\n",
      "\n",
      "Epoch 4/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:56<00:00,  3.44it/s, Loss=0.5974, Acc=83.97%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.48it/s, Acc=85.84%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.43it/s, Acc=84.35%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5974, Train Acc: 83.97%\n",
      "Val Loss: 0.5497, Val Acc: 84.35%\n",
      "Test Loss: 0.5198, Test Acc: 85.84%\n",
      "\n",
      "Epoch 5/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:57<00:00,  3.44it/s, Loss=0.5233, Acc=86.15%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.46it/s, Acc=87.83%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.39it/s, Acc=86.38%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5233, Train Acc: 86.15%\n",
      "Val Loss: 0.4938, Val Acc: 86.38%\n",
      "Test Loss: 0.4661, Test Acc: 87.83%\n",
      "\n",
      "Epoch 6/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:57<00:00,  3.44it/s, Loss=0.4763, Acc=87.51%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.52it/s, Acc=88.57%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.37it/s, Acc=87.09%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4763, Train Acc: 87.51%\n",
      "Val Loss: 0.4652, Val Acc: 87.09%\n",
      "Test Loss: 0.4389, Test Acc: 88.57%\n",
      "\n",
      "Epoch 7/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:57<00:00,  3.44it/s, Loss=0.4477, Acc=88.43%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.47it/s, Acc=89.31%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.44it/s, Acc=88.14%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4477, Train Acc: 88.43%\n",
      "Val Loss: 0.4421, Val Acc: 88.14%\n",
      "Test Loss: 0.4173, Test Acc: 89.31%\n",
      "\n",
      "Epoch 8/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:56<00:00,  3.44it/s, Loss=0.4229, Acc=89.25%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.51it/s, Acc=90.13%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.43it/s, Acc=88.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4229, Train Acc: 89.25%\n",
      "Val Loss: 0.4224, Val Acc: 88.79%\n",
      "Test Loss: 0.3975, Test Acc: 90.13%\n",
      "\n",
      "Epoch 9/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:57<00:00,  3.44it/s, Loss=0.4046, Acc=89.83%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.47it/s, Acc=90.80%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.43it/s, Acc=89.13%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4046, Train Acc: 89.83%\n",
      "Val Loss: 0.4076, Val Acc: 89.13%\n",
      "Test Loss: 0.3828, Test Acc: 90.80%\n",
      "\n",
      "Epoch 10/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:57<00:00,  3.44it/s, Loss=0.3915, Acc=90.26%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.46it/s, Acc=91.21%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.43it/s, Acc=89.70%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3915, Train Acc: 90.26%\n",
      "Val Loss: 0.3962, Val Acc: 89.70%\n",
      "Test Loss: 0.3722, Test Acc: 91.21%\n",
      "\n",
      "Epoch 11/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:56<00:00,  3.44it/s, Loss=0.3815, Acc=90.58%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.51it/s, Acc=91.51%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.36it/s, Acc=89.97%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3815, Train Acc: 90.58%\n",
      "Val Loss: 0.3878, Val Acc: 89.97%\n",
      "Test Loss: 0.3650, Test Acc: 91.51%\n",
      "\n",
      "Epoch 12/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:57<00:00,  3.44it/s, Loss=0.3731, Acc=90.83%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.44it/s, Acc=91.76%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.42it/s, Acc=90.25%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3731, Train Acc: 90.83%\n",
      "Val Loss: 0.3820, Val Acc: 90.25%\n",
      "Test Loss: 0.3590, Test Acc: 91.76%\n",
      "\n",
      "Epoch 13/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:57<00:00,  3.44it/s, Loss=0.3663, Acc=91.06%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.49it/s, Acc=91.74%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.40it/s, Acc=90.44%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3663, Train Acc: 91.06%\n",
      "Val Loss: 0.3775, Val Acc: 90.44%\n",
      "Test Loss: 0.3543, Test Acc: 91.74%\n",
      "\n",
      "Epoch 14/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:56<00:00,  3.44it/s, Loss=0.3607, Acc=91.21%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.45it/s, Acc=91.85%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.40it/s, Acc=90.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3607, Train Acc: 91.21%\n",
      "Val Loss: 0.3724, Val Acc: 90.60%\n",
      "Test Loss: 0.3495, Test Acc: 91.85%\n",
      "\n",
      "Epoch 15/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:57<00:00,  3.44it/s, Loss=0.3547, Acc=91.42%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.46it/s, Acc=92.01%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.43it/s, Acc=90.90%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3547, Train Acc: 91.42%\n",
      "Val Loss: 0.3677, Val Acc: 90.90%\n",
      "Test Loss: 0.3448, Test Acc: 92.01%\n",
      "\n",
      "Epoch 16/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:57<00:00,  3.44it/s, Loss=0.3496, Acc=91.57%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.52it/s, Acc=92.04%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.37it/s, Acc=90.92%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3496, Train Acc: 91.57%\n",
      "Val Loss: 0.3641, Val Acc: 90.92%\n",
      "Test Loss: 0.3412, Test Acc: 92.04%\n",
      "\n",
      "Epoch 17/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:56<00:00,  3.44it/s, Loss=0.3454, Acc=91.80%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.49it/s, Acc=92.28%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.43it/s, Acc=91.26%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3454, Train Acc: 91.80%\n",
      "Val Loss: 0.3588, Val Acc: 91.26%\n",
      "Test Loss: 0.3347, Test Acc: 92.28%\n",
      "\n",
      "Epoch 18/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:56<00:00,  3.44it/s, Loss=0.3409, Acc=91.85%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.47it/s, Acc=92.52%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.38it/s, Acc=91.44%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3409, Train Acc: 91.85%\n",
      "Val Loss: 0.3544, Val Acc: 91.44%\n",
      "Test Loss: 0.3312, Test Acc: 92.52%\n",
      "\n",
      "Epoch 19/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:56<00:00,  3.44it/s, Loss=0.3376, Acc=92.00%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.50it/s, Acc=92.52%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.44it/s, Acc=91.29%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3376, Train Acc: 92.00%\n",
      "Val Loss: 0.3527, Val Acc: 91.29%\n",
      "Test Loss: 0.3295, Test Acc: 92.52%\n",
      "\n",
      "Epoch 20/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:56<00:00,  3.44it/s, Loss=0.3344, Acc=92.06%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.45it/s, Acc=92.74%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.41it/s, Acc=91.41%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3344, Train Acc: 92.06%\n",
      "Val Loss: 0.3480, Val Acc: 91.41%\n",
      "Test Loss: 0.3244, Test Acc: 92.74%\n",
      "\n",
      "Epoch 21/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:56<00:00,  3.44it/s, Loss=0.3305, Acc=92.16%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.45it/s, Acc=92.87%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.35it/s, Acc=91.58%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3305, Train Acc: 92.16%\n",
      "Val Loss: 0.3452, Val Acc: 91.58%\n",
      "Test Loss: 0.3211, Test Acc: 92.87%\n",
      "\n",
      "Epoch 22/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:57<00:00,  3.44it/s, Loss=0.3261, Acc=92.25%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.48it/s, Acc=92.92%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.43it/s, Acc=91.51%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3261, Train Acc: 92.25%\n",
      "Val Loss: 0.3422, Val Acc: 91.51%\n",
      "Test Loss: 0.3180, Test Acc: 92.92%\n",
      "\n",
      "Epoch 23/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:56<00:00,  3.44it/s, Loss=0.3224, Acc=92.40%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.50it/s, Acc=92.95%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.40it/s, Acc=91.53%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3224, Train Acc: 92.40%\n",
      "Val Loss: 0.3393, Val Acc: 91.53%\n",
      "Test Loss: 0.3147, Test Acc: 92.95%\n",
      "\n",
      "Epoch 24/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:56<00:00,  3.44it/s, Loss=0.3186, Acc=92.50%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.46it/s, Acc=93.08%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.42it/s, Acc=91.76%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3186, Train Acc: 92.50%\n",
      "Val Loss: 0.3351, Val Acc: 91.76%\n",
      "Test Loss: 0.3112, Test Acc: 93.08%\n",
      "\n",
      "Epoch 25/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 196/196 [00:57<00:00,  3.44it/s, Loss=0.3156, Acc=92.60%]\n",
      "Testing: 100%|██████████| 40/40 [00:02<00:00, 18.51it/s, Acc=93.13%]\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.43it/s, Acc=91.72%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3156, Train Acc: 92.60%\n",
      "Val Loss: 0.3331, Val Acc: 91.72%\n",
      "Test Loss: 0.3088, Test Acc: 93.13%\n",
      "\n",
      "Epoch 26/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|█████     | 99/196 [00:29<00:28,  3.44it/s, Loss=0.3146, Acc=92.64%]\n",
      "Validation:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/40 [00:00<?, ?it/s, Acc=89.84%]\u001b[A\n",
      "Validation:   0%|          | 0/40 [00:00<?, ?it/s, Acc=91.21%]\u001b[A\n",
      "Validation:   5%|▌         | 2/40 [00:00<00:02, 18.17it/s, Acc=91.21%]\u001b[A\n",
      "Validation:   5%|▌         | 2/40 [00:00<00:02, 18.17it/s, Acc=91.28%]\u001b[A\n",
      "Validation:   5%|▌         | 2/40 [00:00<00:02, 18.17it/s, Acc=91.31%]\u001b[A\n",
      "Validation:  10%|█         | 4/40 [00:00<00:01, 18.08it/s, Acc=91.31%]\u001b[A\n",
      "Validation:  10%|█         | 4/40 [00:00<00:01, 18.08it/s, Acc=91.33%]\u001b[A\n",
      "Validation:  10%|█         | 4/40 [00:00<00:01, 18.08it/s, Acc=91.60%]\u001b[A\n",
      "Validation:  15%|█▌        | 6/40 [00:00<00:01, 18.04it/s, Acc=91.60%]\u001b[A\n",
      "Validation:  15%|█▌        | 6/40 [00:00<00:01, 18.04it/s, Acc=91.96%]\u001b[A\n",
      "Validation:  15%|█▌        | 6/40 [00:00<00:01, 18.04it/s, Acc=91.94%]\u001b[A\n",
      "Validation:  20%|██        | 8/40 [00:00<00:01, 18.05it/s, Acc=91.94%]\u001b[A\n",
      "Validation:  20%|██        | 8/40 [00:00<00:01, 18.05it/s, Acc=91.75%]\u001b[A\n",
      "Validation:  20%|██        | 8/40 [00:00<00:01, 18.05it/s, Acc=91.91%]\u001b[A\n",
      "Validation:  25%|██▌       | 10/40 [00:00<00:01, 18.04it/s, Acc=91.91%]\u001b[A\n",
      "Validation:  25%|██▌       | 10/40 [00:00<00:01, 18.04it/s, Acc=91.58%]\u001b[A\n",
      "Validation:  25%|██▌       | 10/40 [00:00<00:01, 18.04it/s, Acc=91.44%]\u001b[A\n",
      "Validation:  30%|███       | 12/40 [00:00<00:01, 18.05it/s, Acc=91.44%]\u001b[A\n",
      "Validation:  30%|███       | 12/40 [00:00<00:01, 18.05it/s, Acc=91.47%]\u001b[A\n",
      "Validation:  30%|███       | 12/40 [00:00<00:01, 18.05it/s, Acc=91.66%]\u001b[A\n",
      "Validation:  35%|███▌      | 14/40 [00:00<00:01, 18.05it/s, Acc=91.66%]\u001b[A\n",
      "Validation:  35%|███▌      | 14/40 [00:00<00:01, 18.05it/s, Acc=91.61%]\u001b[A\n",
      "Validation:  35%|███▌      | 14/40 [00:00<00:01, 18.05it/s, Acc=91.80%]\u001b[A\n",
      "Validation:  40%|████      | 16/40 [00:00<00:01, 18.04it/s, Acc=91.80%]\u001b[A\n",
      "Validation:  40%|████      | 16/40 [00:00<00:01, 18.04it/s, Acc=91.87%]\u001b[A\n",
      "Validation:  40%|████      | 16/40 [00:00<00:01, 18.04it/s, Acc=91.91%]\u001b[A\n",
      "Validation:  45%|████▌     | 18/40 [00:00<00:01, 18.04it/s, Acc=91.91%]\u001b[A\n",
      "Validation:  45%|████▌     | 18/40 [00:01<00:01, 18.04it/s, Acc=92.00%]\u001b[A\n",
      "Validation:  45%|████▌     | 18/40 [00:01<00:01, 18.04it/s, Acc=92.13%]\u001b[A\n",
      "Validation:  50%|█████     | 20/40 [00:01<00:01, 18.05it/s, Acc=92.13%]\u001b[A\n",
      "Validation:  50%|█████     | 20/40 [00:01<00:01, 18.05it/s, Acc=92.13%]\u001b[A\n",
      "Validation:  50%|█████     | 20/40 [00:01<00:01, 18.05it/s, Acc=91.92%]\u001b[A\n",
      "Validation:  55%|█████▌    | 22/40 [00:01<00:00, 18.04it/s, Acc=91.92%]\u001b[A\n",
      "Validation:  55%|█████▌    | 22/40 [00:01<00:00, 18.04it/s, Acc=91.88%]\u001b[A\n",
      "Validation:  55%|█████▌    | 22/40 [00:01<00:00, 18.04it/s, Acc=91.88%]\u001b[A\n",
      "Validation:  60%|██████    | 24/40 [00:01<00:00, 18.05it/s, Acc=91.88%]\u001b[A\n",
      "Validation:  60%|██████    | 24/40 [00:01<00:00, 18.05it/s, Acc=91.83%]\u001b[A\n",
      "Validation:  60%|██████    | 24/40 [00:01<00:00, 18.05it/s, Acc=91.86%]\u001b[A\n",
      "Validation:  65%|██████▌   | 26/40 [00:01<00:00, 18.05it/s, Acc=91.86%]\u001b[A\n",
      "Validation:  65%|██████▌   | 26/40 [00:01<00:00, 18.05it/s, Acc=91.78%]\u001b[A\n",
      "Validation:  65%|██████▌   | 26/40 [00:01<00:00, 18.05it/s, Acc=91.73%]\u001b[A\n",
      "Validation:  70%|███████   | 28/40 [00:01<00:00, 18.05it/s, Acc=91.73%]\u001b[A\n",
      "Validation:  70%|███████   | 28/40 [00:01<00:00, 18.05it/s, Acc=91.80%]\u001b[A\n",
      "Validation:  70%|███████   | 28/40 [00:01<00:00, 18.05it/s, Acc=91.71%]\u001b[A\n",
      "Validation:  75%|███████▌  | 30/40 [00:01<00:00, 18.06it/s, Acc=91.71%]\u001b[A\n",
      "Validation:  75%|███████▌  | 30/40 [00:01<00:00, 18.06it/s, Acc=91.68%]\u001b[A\n",
      "Validation:  75%|███████▌  | 30/40 [00:01<00:00, 18.06it/s, Acc=91.74%]\u001b[A\n",
      "Validation:  80%|████████  | 32/40 [00:01<00:00, 18.05it/s, Acc=91.74%]\u001b[A\n",
      "Validation:  80%|████████  | 32/40 [00:01<00:00, 18.05it/s, Acc=91.63%]\u001b[A\n",
      "Validation:  80%|████████  | 32/40 [00:01<00:00, 18.05it/s, Acc=91.70%]\u001b[A\n",
      "Validation:  85%|████████▌ | 34/40 [00:01<00:00, 18.04it/s, Acc=91.70%]\u001b[A\n",
      "Validation:  85%|████████▌ | 34/40 [00:01<00:00, 18.04it/s, Acc=91.71%]\u001b[A\n",
      "Validation:  85%|████████▌ | 34/40 [00:01<00:00, 18.04it/s, Acc=91.70%]\u001b[A\n",
      "Validation:  90%|█████████ | 36/40 [00:01<00:00, 18.05it/s, Acc=91.70%]\u001b[A\n",
      "Validation:  90%|█████████ | 36/40 [00:02<00:00, 18.05it/s, Acc=91.69%]\u001b[A\n",
      "Validation:  90%|█████████ | 36/40 [00:02<00:00, 18.05it/s, Acc=91.77%]\u001b[A\n",
      "Validation:  95%|█████████▌| 38/40 [00:02<00:00, 18.03it/s, Acc=91.77%]\u001b[A\n",
      "Validation:  95%|█████████▌| 38/40 [00:02<00:00, 18.03it/s, Acc=91.86%]\u001b[A\n",
      "Validation: 100%|██████████| 40/40 [00:02<00:00, 18.20it/s, Acc=91.84%]\u001b[A\n",
      "Training:  51%|█████     | 100/196 [00:31<00:30,  3.19it/s, Loss=0.3146, Acc=92.64%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5000: Val Acc: 91.84%\n",
      "New best model saved! Validation accuracy: 91.84%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 428\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# Train (returns updated global_step and best_val_acc)\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m train_loss, train_acc, global_step, best_val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_val_acc\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m    433\u001b[0m train_accuracies\u001b[38;5;241m.\u001b[39mappend(train_acc)\n",
      "Cell \u001b[0;32mIn[10], line 359\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, device, global_step, best_val_acc)\u001b[0m\n\u001b[1;32m    357\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m    358\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m--> 359\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    362\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# Added Validation\n",
    "# Type definitions\n",
    "InitializationType = Literal['residual', 'random']\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 256\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "k = 16  # Base number of kernels (from paper: k=16 for small model)\n",
    "\n",
    "print(f\"Base kernel count k = {k}\")\n",
    "print(f\"Expected shapes from paper:\")\n",
    "print(f\"After conv1 + pool1: {k} × 12 × 12\")\n",
    "print(f\"After conv2 + pool2: {3*k} × 6 × 6\") \n",
    "print(f\"After conv3 + pool3: {9*k} × 3 × 3\")\n",
    "print(f\"After flattening: {81*k}\")\n",
    "\n",
    "# Data loading and preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "full_train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "# Split into 50k train and 10k validation\n",
    "train_size = 50000\n",
    "val_size = 10000\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_train_dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Logic gate definitions\n",
    "logic_gates = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "\n",
    "def apply_logic_gate(a: torch.Tensor, b: torch.Tensor, logic_gate: int):\n",
    "    return {\n",
    "        0:  torch.zeros_like(a),\n",
    "        1:  a * b,\n",
    "        2:  a - a * b,\n",
    "        3:  a,\n",
    "        4:  b - a * b,\n",
    "        5:  b,\n",
    "        6:  a + b - 2 * a * b,\n",
    "        7:  a + b - a * b,\n",
    "        8:  1 - (a + b - a * b),\n",
    "        9:  1 - (a + b - 2 * a * b),\n",
    "        10: 1 - b,\n",
    "        11: 1 - b + a * b,\n",
    "        12: 1 - a,\n",
    "        13: 1 - a + a * b,\n",
    "        14: 1 - a * b,\n",
    "        15: torch.ones_like(a),\n",
    "    }[logic_gate]\n",
    "\n",
    "class Logic(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim: int,\n",
    "                 out_dim: int,\n",
    "                 initialization_type: InitializationType = 'residual',\n",
    "                 device=None\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.initialization_type = initialization_type\n",
    "        self.device = device or torch.device('cpu')\n",
    "        \n",
    "        a, b = self.get_connections()\n",
    "        self.register_buffer('a', a)\n",
    "        self.register_buffer('b', b)\n",
    "        \n",
    "        weights = torch.randn(out_dim, len(logic_gates), device=self.device)\n",
    "        if self.initialization_type == 'residual':\n",
    "            weights[:, :] = 0\n",
    "            weights[:, 3] = 5  # Initialize to identity gate\n",
    "        self.weights = torch.nn.parameter.Parameter(weights)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        a, b = x[:, self.a, ...], x[:, self.b, ...]\n",
    "        \n",
    "        if self.training:\n",
    "            normalized_weights = torch.nn.functional.softmax(self.weights, dim=-1).to(x.dtype).to(self.device)\n",
    "            r = torch.zeros_like(a).to(x.dtype).to(self.device)\n",
    "            for logic_gate in logic_gates:\n",
    "                if len(a.shape) > 2:\n",
    "                    nw = einops.repeat(normalized_weights[..., logic_gate], 'weights -> weights depth', depth=a.shape[-1])\n",
    "                else:\n",
    "                    nw = normalized_weights[..., logic_gate]\n",
    "                r = r + nw * apply_logic_gate(a, b, logic_gate)\n",
    "            return r\n",
    "        else:\n",
    "            one_hot_weights = torch.nn.functional.one_hot(self.weights.argmax(-1), len(logic_gates)).to(torch.float32).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                r = torch.zeros_like(a).to(x.dtype).to(self.device)\n",
    "                for logic_gate in logic_gates:\n",
    "                    if len(a.shape) > 2:\n",
    "                        ohw = einops.repeat(one_hot_weights[..., logic_gate], 'weights -> weights depth', depth=a.shape[-1])\n",
    "                    else:\n",
    "                        ohw = one_hot_weights[..., logic_gate]\n",
    "                    r = r + ohw * apply_logic_gate(a, b, logic_gate)\n",
    "                return r\n",
    "\n",
    "    def get_connections(self):\n",
    "        connections = torch.randperm(2 * self.out_dim) % self.in_dim\n",
    "        connections = torch.randperm(self.in_dim)[connections]\n",
    "        connections = connections.reshape(2, self.out_dim)\n",
    "        a, b = connections[0], connections[1]\n",
    "        a, b = a.to(torch.int64), b.to(torch.int64)\n",
    "        a, b = a.to(self.device), b.to(self.device)\n",
    "        return a, b\n",
    "\n",
    "class LogicTree(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim: int,\n",
    "                 depth: int = 3,\n",
    "                 initialization_type: InitializationType = 'residual',\n",
    "                 device=None,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.device = device or torch.device('cpu')\n",
    "        \n",
    "        layers = [LogicLayer(in_dim, int(2 ** (depth - 1)), initialization_type=initialization_type, device=self.device,implementation='cuda' if device.type == 'cuda' else 'python',\n",
    "                    connections='random',grad_factor=1.5 )]\n",
    "        for i in range(0, depth - 1, 1):\n",
    "            layers.append(LogicLayer(int(2 ** (depth - 1 - i)), int(2 ** (depth - 1 - i - 1)), \n",
    "                            initialization_type=initialization_type, device=self.device,implementation='cuda' if device.type == 'cuda' else 'python',\n",
    "                            connections='random',grad_factor=1.5))\n",
    "        \n",
    "        self.tree = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.tree(x)\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 depth: int = 3,\n",
    "                 kernel_size: int = 3,\n",
    "                 stride: int = 1,\n",
    "                 padding: int = 1,\n",
    "                 initialization_type: InitializationType = 'residual',\n",
    "                 device=None\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.device = device or torch.device('cpu')\n",
    "        \n",
    "        self.filters = nn.ModuleList([\n",
    "            LogicTree(in_dim=kernel_size ** 2 * in_channels, depth=depth, \n",
    "                     initialization_type=initialization_type, device=self.device) \n",
    "            for _ in range(out_channels)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, _, height, width = x.shape\n",
    "        x = F.pad(x, (self.padding, self.padding, self.padding, self.padding), mode='constant', value=0)\n",
    "        out_height = (height + 2 * self.padding - self.kernel_size) // self.stride + 1\n",
    "        out_width = (width + 2 * self.padding - self.kernel_size) // self.stride + 1\n",
    "        patches = F.unfold(x, kernel_size=self.kernel_size, stride=self.stride)\n",
    "        outputs = []\n",
    "        \n",
    "        patches = einops.rearrange(patches, 'b h w -> (b w) h', h=patches.shape[1], w=patches.shape[2]) # Input is (100,25,576) Output: (57600,25)\n",
    "        for filter in self.filters:\n",
    "            out = filter(patches)  # Shape: (batch_size, 1, out_height * out_width)\n",
    "            out = einops.rearrange(out, '(b h w) 1 -> b (h w)', h=out_height, w=out_width)\n",
    "            outputs.append(out)\n",
    "        \n",
    "        output_tensor = torch.stack(outputs, dim=1)  # Shape: (batch_size, out_channels, out_height * out_width)\n",
    "        output_tensor = einops.rearrange(output_tensor, 'b c (h w) -> b c h w', h=out_height, w=out_width)\n",
    "        return output_tensor\n",
    "\n",
    "class CustomOrPool2d(nn.Module):\n",
    "    def __init__(self, kernel_size=2, stride=2, padding=0):\n",
    "        super(CustomOrPool2d, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Use MaxPool2d as approximation to OR pooling\n",
    "        # In binary logic, max operation approximates OR\n",
    "        return torch.max_pool2d(x, self.kernel_size, self.stride, self.padding)\n",
    "\n",
    "\n",
    "\n",
    "class ConvDiffLogicMNIST(nn.Module):\n",
    "    def __init__(self, k=16):\n",
    "        super(ConvDiffLogicMNIST, self).__init__()\n",
    "        self.k = k\n",
    "        \n",
    "        # Convolutional block 1: k kernels, 5x5, depth=3, no padding\n",
    "        # Input: 1 × 28 × 28 -> Output: k × 24 × 24 (28-5+1=24)\n",
    "        self.conv1 = Conv(in_channels=1, out_channels=k, kernel_size=5, depth=3, \n",
    "                         padding=0, initialization_type='residual', device=device)\n",
    "        \n",
    "        # OR pooling 1: 2x2, stride 2\n",
    "        # k × 24 × 24 -> k × 12 × 12\n",
    "        self.pool1 = CustomOrPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Convolutional block 2: 3*k kernels, 3x3, depth=3\n",
    "        # k × 12 × 12 -> 3*k × 12 × 12 (with padding=1), then pooled to 3*k × 6 × 6\n",
    "        self.conv2 = Conv(in_channels=k, out_channels=3*k, kernel_size=3, depth=3, \n",
    "                         padding=1, initialization_type='residual', device=device)\n",
    "        \n",
    "        # OR pooling 2: 2x2, stride 2\n",
    "        # 3*k × 12 × 12 -> 3*k × 6 × 6\n",
    "        self.pool2 = CustomOrPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Convolutional block 3: 9*k kernels, 3x3, depth=3\n",
    "        # 3*k × 6 × 6 -> 9*k × 6 × 6 (with padding=1), then pooled to 9*k × 3 × 3\n",
    "        self.conv3 = Conv(in_channels=3*k, out_channels=9*k, kernel_size=3, depth=3, \n",
    "                         padding=1, initialization_type='residual', device=device)\n",
    "        \n",
    "        # OR pooling 3: 2x2, stride 2\n",
    "        # 9*k × 6 × 6 -> 9*k × 3 × 3\n",
    "        self.pool3 = CustomOrPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Flatten: 9*k × 3 × 3 -> 81*k\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Regular differentiable logic layers (as specified in paper)\n",
    "        # 81*k → 1280*k\n",
    "        self.fc1 = LogicLayer(\n",
    "            in_dim=81*k,\n",
    "            out_dim=1280*k,\n",
    "            device=device,\n",
    "            implementation='cuda' if device.type == 'cuda' else 'python',\n",
    "            connections='random',\n",
    "            grad_factor=1.5 , # Higher for deeper networks\n",
    "        )\n",
    "        \n",
    "        # 1280*k → 640*k\n",
    "        self.fc2 = LogicLayer(\n",
    "            in_dim=1280*k,\n",
    "            out_dim=640*k,\n",
    "            device=device,\n",
    "            implementation='cuda' if device.type == 'cuda' else 'python',\n",
    "            connections='random',\n",
    "            grad_factor=1.5\n",
    "        )\n",
    "        \n",
    "        # 640*k → 320*k\n",
    "        self.fc3 = LogicLayer(\n",
    "            in_dim=640*k,\n",
    "            out_dim=320*k,\n",
    "            device=device,\n",
    "            implementation='cuda' if device.type == 'cuda' else 'python',\n",
    "            connections='random',\n",
    "            grad_factor=1.5\n",
    "        )\n",
    "        \n",
    "        # GroupSum: 320*k → 10 (10 classes)\n",
    "        # Using tau=30 as in the paper specifications\n",
    "        self.group_sum = GroupSum(k=10, tau=30)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input thresholding for binary processing (as mentioned in paper)\n",
    "        # STE for binary inputs - FIXED GRADIENT FLOW\n",
    "        x_bin = (x > 0.5).float()\n",
    "        x = x + (x_bin - x).detach()\n",
    "        \n",
    "        # Debug shape printing (uncomment for debugging)\n",
    "        # print(f\"Input shape: {x.shape}\")\n",
    "        \n",
    "        # Convolutional processing with logic gates\n",
    "        x = self.conv1(x)\n",
    "        # print(f\"After conv1: {x.shape}\")\n",
    "        \n",
    "        x = self.pool1(x)\n",
    "        # print(f\"After pool1: {x.shape}\")\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        # print(f\"After conv2: {x.shape}\")\n",
    "        \n",
    "        x = self.pool2(x)\n",
    "        # print(f\"After pool2: {x.shape}\")\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        # print(f\"After conv3: {x.shape}\")\n",
    "        \n",
    "        x = self.pool3(x)\n",
    "        # print(f\"After pool3: {x.shape}\")\n",
    "        \n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "        # print(f\"After flatten: {x.shape}\")\n",
    "        \n",
    "        # Fully connected logic layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # GroupSum for classification\n",
    "        x = self.group_sum(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = ConvDiffLogicMNIST(k=k).to(device)\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "\n",
    "# Print architecture details\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOGIC GATE CONVOLUTIONAL DIFFLOGIC MNIST\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Input: 1 × 28 × 28\")\n",
    "print(f\"Conv1: {k} logic gate filters, 5×5, depth=3, no padding -> {k} × 24 × 24\")\n",
    "print(f\"Pool1: OR pooling 2×2, stride 2 -> {k} × 12 × 12\")\n",
    "print(f\"Conv2: {3*k} logic gate filters, 3×3, depth=3 -> {3*k} × 12 × 12\")\n",
    "print(f\"Pool2: OR pooling 2×2, stride 2 -> {3*k} × 6 × 6\")\n",
    "print(f\"Conv3: {9*k} logic gate filters, 3×3, depth=3 -> {9*k} × 6 × 6\")\n",
    "print(f\"Pool3: OR pooling 2×2, stride 2 -> {9*k} × 3 × 3\")\n",
    "print(f\"Flatten: -> {81*k}\")\n",
    "print(f\"FC1: Regular differentiable logic layer {81*k} -> {1280*k}\")\n",
    "print(f\"FC2: Regular differentiable logic layer {1280*k} -> {640*k}\")\n",
    "print(f\"FC3: Regular differentiable logic layer {640*k} -> {320*k}\")\n",
    "print(f\"GroupSum: {320*k} -> 10 classes\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, train_loader, val_loader, criterion, optimizer, device, global_step, best_val_acc):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc='Training')\n",
    "    for batch_idx, (data, target) in enumerate(progress_bar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
    "            'Acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "        \n",
    "        # Update global step\n",
    "        global_step += 1\n",
    "        \n",
    "        # Validate every 5000 steps\n",
    "        if global_step % 5000 == 0:\n",
    "            val_loss, val_acc = evaluate(model, val_loader, criterion, device, desc='Validation')\n",
    "            print(f\"Step {global_step}: Val Acc: {val_acc:.2f}%\")\n",
    "            \n",
    "            # Save best model based on validation accuracy\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save(model.state_dict(), 'best_logic_conv_difflogic_mnist_val.pth')\n",
    "                print(f\"New best model saved! Validation accuracy: {val_acc:.2f}%\")\n",
    "    \n",
    "    return running_loss / len(train_loader), 100. * correct / total, global_step, best_val_acc\n",
    "\n",
    "def evaluate(model, loader, criterion, device, desc='Evaluating'):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(loader, desc=desc)\n",
    "        for data, target in progress_bar:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'Acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    return test_loss / len(loader), 100. * correct / total\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Starting training with logic gate convolutions...\")\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    best_val_acc = 0.0  # Track best validation accuracy\n",
    "    global_step = 0     # Global training step counter\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Train (returns updated global_step and best_val_acc)\n",
    "        train_loss, train_acc, global_step, best_val_acc = train_epoch(\n",
    "            model, train_loader, val_loader, criterion, optimizer, device, \n",
    "            global_step, best_val_acc\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_loss, test_acc = evaluate(model, test_loader, criterion, device, desc='Testing')\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device, desc='Validation')\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {total_time:.2f} seconds\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "\n",
    "    # Load best model for final evaluation\n",
    "    model.load_state_dict(torch.load('best_logic_conv_difflogic_mnist_val.pth'))\n",
    "    print(\"Loaded best model based on validation accuracy\")\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    print(\"\\nEvaluating best model on test set...\")\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device, desc='Final Test')\n",
    "    print(f\"Best model test accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "    # Test discrete inference\n",
    "    print(\"\\nTesting discrete inference...\")\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    inference_time = time.time() - start_time\n",
    "    inference_speed = inference_time / total\n",
    "\n",
    "    print(f\"Discrete inference accuracy: {100. * correct / total:.2f}%\")\n",
    "    print(f\"Inference speed: {inference_speed:.6f} seconds per sample\")\n",
    "\n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), 'final_logic_conv_difflogic_mnist.pth')\n",
    "\n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LOGIC GATE CONVOLUTIONAL DIFFLOGIC MNIST RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"Final test accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"Inference speed: {inference_speed:.6f} seconds per sample\")\n",
    "    print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
